<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 1800.0 945.0">
  <ns0:defs>
    <ns0:linearGradient id="bgPG" x1="0%" y1="0%" x2="100%" y2="100%">
      <ns0:stop offset="0%" style="stop-color:#ffffff"/>
      <ns0:stop offset="100%" style="stop-color:#2d2d2d"/>
    </ns0:linearGradient>
  </ns0:defs>
  <ns0:rect width="1800.0" height="945.0" fill="#f8f9fa" rx="8"/>
  <ns0:text x="400" y="35" text-anchor="middle" fill="#1a237e" font-size="22" font-weight="bold">Policy Gradient Methods</ns0:text>
  <ns0:g transform="translate(50, 70)">
    <ns0:text x="100" y="60.0" text-anchor="middle" fill="#e65100" font-size="14" font-weight="bold">Policy Network Ï€_Î¸(a|s)</ns0:text>
    <ns0:rect x="0" y="30" width="60" height="100" rx="5" fill="#1565c0" stroke="#007bff"/>
    <ns0:text x="30" y="80" text-anchor="middle" fill="#1a237e" font-size="11">State s</ns0:text>
    <ns0:rect x="80" y="20" width="100" height="120" rx="10" fill="#8b5cf6" stroke="#a78bfa" stroke-width="2"/>
    <ns0:text x="130" y="105.0" text-anchor="middle" fill="#1a237e" font-size="10">Neural</ns0:text>
    <ns0:text x="130" y="130.0" text-anchor="middle" fill="#1a237e" font-size="10">Network</ns0:text>
    <ns0:line x1="60" y1="80" x2="80" y2="80" stroke="#6366f1" stroke-width="2" marker-end="url(#arrow)"/>
    <ns0:line x1="180" y1="80" x2="200" y2="80" stroke="#6366f1" stroke-width="2" marker-end="url(#arrow)"/>
    <ns0:rect x="200" y="30" width="80" height="100" rx="5" fill="#10b981" stroke="#28a745"/>
    <ns0:text x="240" y="155.0" text-anchor="middle" fill="#1a237e" font-size="10">Action</ns0:text>
    <ns0:text x="240" y="180.0" text-anchor="middle" fill="#1a237e" font-size="10">Probs</ns0:text>
    <ns0:text x="240" y="205.0" text-anchor="middle" fill="#d1fae5" font-size="9">aâ‚: 0.6</ns0:text>
    <ns0:text x="240" y="230.0" text-anchor="middle" fill="#d1fae5" font-size="9">aâ‚‚: 0.4</ns0:text>
  </ns0:g>
  <ns0:g transform="translate(350, 70)">
    <ns0:rect width="400" height="130" rx="10" fill="#2d2d2d20" stroke="#fd7e14" stroke-width="2"/>
    <ns0:text x="200" y="255.0" text-anchor="middle" fill="#e65100" font-size="14" font-weight="bold">REINFORCE Update (Vanilla PG)</ns0:text>
    <ns0:text x="200" y="280.0" text-anchor="middle" fill="#1a237e" font-size="13" font-family="Arial, sans-serif">âˆ‡_Î¸ J(Î¸) = ğ”¼[Î£â‚œ âˆ‡_Î¸ log Ï€_Î¸(aâ‚œ|sâ‚œ) Â· Gâ‚œ]</ns0:text>
    <ns0:text x="80" y="305.0" fill="#1565c0" font-size="10">log probability</ns0:text>
    <ns0:text x="250" y="330.0" fill="#2e7d32" font-size="10">return (reward)</ns0:text>
    <ns0:text x="200" y="355.0" text-anchor="middle" fill="#e65100" font-size="10">â†‘ prob of actions that led to high returns</ns0:text>
  </ns0:g>
  <ns0:g transform="translate(50, 220)">
    <ns0:rect width="340" height="100" rx="10" fill="#2d2d2d20" stroke="#007bff"/>
    <ns0:text x="170" y="380.0" text-anchor="middle" fill="#1565c0" font-size="13" font-weight="bold">Baseline (Variance Reduction)</ns0:text>
    <ns0:text x="170" y="405.0" text-anchor="middle" fill="#1a237e" font-size="12" font-family="Arial, sans-serif">âˆ‡_Î¸ J = ğ”¼[âˆ‡_Î¸ log Ï€(a|s) Â· (Gâ‚œ - b(sâ‚œ))]</ns0:text>
    <ns0:text x="170" y="430.0" text-anchor="middle" fill="#1565c0" font-size="10">b(s) = V(s) â†’ Actor-Critic!</ns0:text>
  </ns0:g>
  <ns0:g transform="translate(410, 220)">
    <ns0:rect width="340" height="100" rx="10" fill="#2d2d2d20" stroke="#10b981"/>
    <ns0:text x="170" y="455.0" text-anchor="middle" fill="#2e7d32" font-size="13" font-weight="bold">Actor-Critic: Advantage</ns0:text>
    <ns0:text x="170" y="480.0" text-anchor="middle" fill="#1a237e" font-size="12" font-family="Arial, sans-serif">Aáµ¢(s,a) = Qáµ¢(s,a) - Váµ¢(s)</ns0:text>
    <ns0:text x="170" y="505.0" text-anchor="middle" fill="#2e7d32" font-size="10">How much better is action a than average?</ns0:text>
  </ns0:g>
  <ns0:g transform="translate(50, 340)">
    <ns0:rect width="700" height="60" rx="10" fill="#1a237e" stroke="#e0e0e0"/>
    <ns0:text x="350" y="530.0" text-anchor="middle" fill="#e65100" font-size="12" font-weight="bold">Policy Gradient vs Value Methods</ns0:text>
    <ns0:text x="350" y="555.0" text-anchor="middle" fill="#1a237e" font-size="11">
      <ns0:tspan x="350" dy="0">PG directly optimizes policy â†’ handles continuous actions,</ns0:tspan>
      <ns0:tspan x="350" dy="1.2em">stochastic policies | Value methods learn Q then derive Ï€</ns0:tspan>
    </ns0:text>
  </ns0:g>
</ns0:svg>