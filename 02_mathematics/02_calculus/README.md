<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=00C853&height=120&section=header&text=Calculus&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-02-00C853?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## ğŸ¯ Visual Overview

<img src="./images/gradient-descent.svg" width="100%">

*Caption: Gradient descent follows the negative gradient to find minima. The gradient âˆ‡f points in the direction of steepest ascent, so we move in the opposite direction. This is the core algorithm behind all neural network training.*

---

## ğŸ“ Mathematical Foundations

### Derivatives

```
Single variable:
df/dx = lim_{hâ†’0} (f(x+h) - f(x)) / h

Partial derivative:
âˆ‚f/âˆ‚xáµ¢ = lim_{hâ†’0} (f(x + heáµ¢) - f(x)) / h

```

### Gradient Vector

```
âˆ‡f(x) = [âˆ‚f/âˆ‚xâ‚, âˆ‚f/âˆ‚xâ‚‚, ..., âˆ‚f/âˆ‚xâ‚™]áµ€

Properties:
â€¢ Points in direction of steepest ascent
â€¢ |âˆ‡f| = rate of steepest increase
â€¢ âˆ‡f âŠ¥ level sets

```

### Jacobian and Hessian

```
For f: â„â¿ â†’ â„áµ:
J = [âˆ‚fáµ¢/âˆ‚xâ±¼]  (m Ã— n matrix)

For f: â„â¿ â†’ â„:
H = [âˆ‚Â²f/âˆ‚xáµ¢âˆ‚xâ±¼]  (n Ã— n matrix)

Positive definite H âŸ¹ local minimum

```

### Chain Rule (Multivariate)

```
If y = f(u) and u = g(x):
âˆ‚y/âˆ‚x = (âˆ‚y/âˆ‚u)(âˆ‚u/âˆ‚x) = Jacobians multiply!

Backpropagation:
âˆ‚L/âˆ‚W = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚z Â· âˆ‚z/âˆ‚W

```

---

## ğŸ“ DETAILED CALCULUS MATHEMATICS

### 1. Multivariable Chain Rule: Complete Derivation

**Single Variable Chain Rule:**

```
If y = f(u) and u = g(x), then:
  dy/dx = dy/du Â· du/dx

Proof:
  dy/dx = lim_{hâ†’0} (f(g(x+h)) - f(g(x))) / h
  
  Let Î”u = g(x+h) - g(x)
  
  = lim_{hâ†’0} (f(g(x)+Î”u) - f(g(x))) / h
  = lim_{hâ†’0} [(f(g(x)+Î”u) - f(g(x))) / Î”u] Â· [Î”u / h]
  = lim_{hâ†’0} (f(g(x)+Î”u) - f(g(x))) / Î”u Â· lim_{hâ†’0} Î”u/h
  = f'(g(x)) Â· g'(x)
  = dy/du Â· du/dx  âœ“

```

**Vector Chain Rule (Key for Backpropagation):**

```
Case 1: Scalar function of vector
  y = f(u), u = g(x)
  y âˆˆ â„, u âˆˆ â„áµ, x âˆˆ â„â¿

Chain rule:
  âˆ‚y/âˆ‚xâ±¼ = Î£áµ¢ (âˆ‚y/âˆ‚uáµ¢)(âˆ‚uáµ¢/âˆ‚xâ±¼)

Matrix form:
  âˆ‡â‚“y = (âˆ‚u/âˆ‚x)áµ€ âˆ‡áµ¤y
      = Jáµ¤,â‚“áµ€ Â· âˆ‡áµ¤y

```

**Proof of Vector Chain Rule:**

```
Step 1: Taylor expansion
  y(x + Î”x) â‰ˆ y(x) + âˆ‡â‚“y Â· Î”x

Step 2: Express through intermediate variable
  u(x + Î”x) â‰ˆ u(x) + Jáµ¤,â‚“ Â· Î”x
  y(u + Î”u) â‰ˆ y(u) + âˆ‡áµ¤y Â· Î”u

Step 3: Substitute
  y(x + Î”x) â‰ˆ y(x) + âˆ‡áµ¤y Â· (Jáµ¤,â‚“ Â· Î”x)
              = y(x) + (âˆ‡áµ¤y)áµ€Jáµ¤,â‚“ Â· Î”x
              = y(x) + (Jáµ¤,â‚“áµ€âˆ‡áµ¤y) Â· Î”x

Step 4: Compare with Taylor expansion
  âˆ‡â‚“y = Jáµ¤,â‚“áµ€ Â· âˆ‡áµ¤y  âœ“

This is the foundation of backpropagation!

```

---

### 2. Backpropagation as Repeated Chain Rule

**Neural Network:**

```
Input:  x âˆˆ â„áµˆâ°
Layer 1: zâ½Â¹â¾ = Wâ½Â¹â¾x + bâ½Â¹â¾ âˆˆ â„áµˆÂ¹
         aâ½Â¹â¾ = Ïƒ(zâ½Â¹â¾)
Layer 2: zâ½Â²â¾ = Wâ½Â²â¾aâ½Â¹â¾ + bâ½Â²â¾ âˆˆ â„áµˆÂ²
         aâ½Â²â¾ = Ïƒ(zâ½Â²â¾)
...
Layer L: zâ½á´¸â¾ = Wâ½á´¸â¾aâ½á´¸â»Â¹â¾ + bâ½á´¸â¾
         Å· = aâ½á´¸â¾ = Ïƒ(zâ½á´¸â¾)

Loss: L = loss(Å·, y)

```

**Goal: Compute âˆ‚L/âˆ‚Wâ½Ë¡â¾ for all layers l**

**Step-by-Step Chain Rule:**

```
Layer L (output):
  âˆ‚L/âˆ‚zâ½á´¸â¾ = âˆ‚L/âˆ‚Å· Â· âˆ‚Å·/âˆ‚zâ½á´¸â¾
           = âˆ‚L/âˆ‚Å· âŠ™ Ïƒ'(zâ½á´¸â¾)

Layer l < L (hidden):
  âˆ‚L/âˆ‚zâ½Ë¡â¾ = âˆ‚L/âˆ‚zâ½Ë¡âºÂ¹â¾ Â· âˆ‚zâ½Ë¡âºÂ¹â¾/âˆ‚aâ½Ë¡â¾ Â· âˆ‚aâ½Ë¡â¾/âˆ‚zâ½Ë¡â¾
           = [(Wâ½Ë¡âºÂ¹â¾)áµ€ Â· âˆ‚L/âˆ‚zâ½Ë¡âºÂ¹â¾] âŠ™ Ïƒ'(zâ½Ë¡â¾)

Weight gradient:
  âˆ‚L/âˆ‚Wâ½Ë¡â¾ = âˆ‚L/âˆ‚zâ½Ë¡â¾ Â· âˆ‚zâ½Ë¡â¾/âˆ‚Wâ½Ë¡â¾
           = âˆ‚L/âˆ‚zâ½Ë¡â¾ Â· (aâ½Ë¡â»Â¹â¾)áµ€  [outer product]

```

**Formal Proof for Layer l:**

```
Let L(Wâ½Ë¡â¾) be the loss

Change Wâ½Ë¡â¾ by Î´Wâ½Ë¡â¾:
  Î´zâ½Ë¡â¾ = Î´Wâ½Ë¡â¾ Â· aâ½Ë¡â»Â¹â¾
  Î´aâ½Ë¡â¾ = Ïƒ'(zâ½Ë¡â¾) âŠ™ Î´zâ½Ë¡â¾
  Î´zâ½Ë¡âºÂ¹â¾ = Wâ½Ë¡âºÂ¹â¾ Â· Î´aâ½Ë¡â¾
  ...
  Î´L = (âˆ‚L/âˆ‚Å·)áµ€ Â· Î´Å·

Working backwards (chain rule):
  Î´L = (âˆ‚L/âˆ‚Å·)áµ€ Â· Î´Å·
     = (âˆ‚L/âˆ‚Å·)áµ€ Â· (âˆ‚Å·/âˆ‚zâ½á´¸â¾) Â· Î´zâ½á´¸â¾
     = ...  [continue backwards]
     = [(âˆ‚L/âˆ‚zâ½Ë¡â¾)áµ€ Â· Î´Wâ½Ë¡â¾] Â· aâ½Ë¡â»Â¹â¾

Therefore:
  âˆ‚L/âˆ‚Wâ½Ë¡â¾ = âˆ‚L/âˆ‚zâ½Ë¡â¾ Â· (aâ½Ë¡â»Â¹â¾)áµ€  âœ“

```

---

### 3. Jacobian Matrix: Theory and Computation

**Definition:**

```
For f: â„â¿ â†’ â„áµ, the Jacobian is:

J = [âˆ‚fáµ¢/âˆ‚xâ±¼] âˆˆ â„áµË£â¿

     +                           +
     | âˆ‚fâ‚/âˆ‚xâ‚  âˆ‚fâ‚/âˆ‚xâ‚‚  ...    |
J =  | âˆ‚fâ‚‚/âˆ‚xâ‚  âˆ‚fâ‚‚/âˆ‚xâ‚‚  ...    |
     |    â‹®        â‹®      â‹±      |
     | âˆ‚fâ‚˜/âˆ‚xâ‚  âˆ‚fâ‚˜/âˆ‚xâ‚‚  ...    |
     +                           +

Interpretation: How each output changes with each input

```

**Chain Rule with Jacobians:**

```
If z = f(y) and y = g(x):
  z: â„áµ– â†’ â„
  y: â„â¿ â†’ â„áµ  
  x: â„â¿

Jacobian chain rule:
  J_{z,x} = J_{z,y} Â· J_{y,x}
  
Dimensions: (pÃ—n) = (pÃ—m) Â· (mÃ—n)  âœ“

```

**Example: Batch Normalization:**

```
Input: x âˆˆ â„â¿
Output: y = (x - Î¼) / âˆš(ÏƒÂ² + Îµ)

where Î¼ = mean(x), ÏƒÂ² = var(x)

Jacobian: âˆ‚yáµ¢/âˆ‚xâ±¼ = ?

Step 1: âˆ‚Î¼/âˆ‚xâ±¼ = 1/n

Step 2: âˆ‚ÏƒÂ²/âˆ‚xâ±¼ = 2(xâ±¼ - Î¼)/n

Step 3: Apply chain rule
  âˆ‚yáµ¢/âˆ‚xâ±¼ = âˆ‚yáµ¢/âˆ‚xáµ¢ Â· âˆ‚xáµ¢/âˆ‚xâ±¼  [direct]
           + âˆ‚yáµ¢/âˆ‚Î¼ Â· âˆ‚Î¼/âˆ‚xâ±¼    [through mean]
           + âˆ‚yáµ¢/âˆ‚ÏƒÂ² Â· âˆ‚ÏƒÂ²/âˆ‚xâ±¼  [through variance]

Full calculation:
  J = (1/âˆš(ÏƒÂ²+Îµ)) Â· [I - (1/n)11áµ€ - (1/n)(x-Î¼)(x-Î¼)áµ€/(ÏƒÂ²+Îµ)]

where 1 is vector of ones

```

---

### 4. Hessian Matrix: Second-Order Information

**Definition:**

```
For f: â„â¿ â†’ â„, the Hessian is:

H = âˆ‡Â²f = [âˆ‚Â²f/âˆ‚xáµ¢âˆ‚xâ±¼] âˆˆ â„â¿Ë£â¿

     +                                    +
     | âˆ‚Â²f/âˆ‚xâ‚Â²    âˆ‚Â²f/âˆ‚xâ‚âˆ‚xâ‚‚   ...      |
H =  | âˆ‚Â²f/âˆ‚xâ‚‚âˆ‚xâ‚  âˆ‚Â²f/âˆ‚xâ‚‚Â²     ...      |
     |     â‹®            â‹®         â‹±       |
     +                                    +

If f is CÂ²: âˆ‚Â²f/âˆ‚xáµ¢âˆ‚xâ±¼ = âˆ‚Â²f/âˆ‚xâ±¼âˆ‚xáµ¢  [Schwarz's theorem]
Therefore: H is symmetric

```

**Taylor Series (Second-Order):**

```
f(x + h) â‰ˆ f(x) + âˆ‡f(x)áµ€h + Â½háµ€H(x)h

This is quadratic approximation!

At critical point (âˆ‡f(x) = 0):
  f(x + h) â‰ˆ f(x) + Â½háµ€H(x)h

Classification:
  H â‰» 0 (positive definite) â†’ local minimum
  H â‰º 0 (negative definite) â†’ local maximum
  H indefinite              â†’ saddle point

```

**Newton's Method:**

```
Use second-order Taylor approximation:
  f(x + h) â‰ˆ f(x) + âˆ‡f(x)áµ€h + Â½háµ€H(x)h

Minimize w.r.t. h:
  âˆ‡â‚•[f(x) + âˆ‡f(x)áµ€h + Â½háµ€H(x)h] = 0
  âˆ‡f(x) + H(x)h = 0
  h = -H(x)â»Â¹âˆ‡f(x)

Newton's update:
  xâ‚™â‚‘w = xâ‚’â‚—d - Hâ»Â¹âˆ‡f

Convergence: Quadratic near minimum
  ||xâ‚™â‚‘w - x*|| = O(||xâ‚’â‚—d - x*||Â²)

Problem: O(nÂ³) to compute Hâ»Â¹

```

---

### 5. Directional Derivatives and Gradient

**Directional Derivative:**

```
Rate of change of f in direction v:
  D_v f(x) = lim_{tâ†’0} (f(x + tv) - f(x)) / t

Theorem: If f differentiable, then:
  D_v f(x) = âˆ‡f(x) Â· v

Proof:
  f(x + tv) â‰ˆ f(x) + âˆ‡f(x)áµ€(tv)
  (f(x + tv) - f(x)) / t â‰ˆ âˆ‡f(x)áµ€v  âœ“

```

**Gradient as Direction of Steepest Ascent:**

```
Theorem: âˆ‡f(x) points in direction of maximum increase

Proof:
  D_v f = âˆ‡f Â· v = ||âˆ‡f|| Â· ||v|| Â· cos(Î¸)

  Maximum when cos(Î¸) = 1, i.e., v âˆ¥ âˆ‡f

  max_||v||=1 D_v f = ||âˆ‡f||

Direction: v* = âˆ‡f / ||âˆ‡f||  âœ“

This is why gradient descent works!
  Move in -âˆ‡f direction to minimize

```

**Gradient Perpendicular to Level Sets:**

```
Theorem: âˆ‡f(x) is perpendicular to level set

Proof:
Let Î³(t) be curve on level set: f(Î³(t)) = c

Differentiate:
  d/dt f(Î³(t)) = âˆ‡f(Î³(t)) Â· Î³'(t) = 0

Since Î³'(t) is tangent to level set and âˆ‡f Â· Î³' = 0:
  âˆ‡f âŠ¥ level set  âœ“

Visualization:
  Level curves of f(x,y) = c
  Gradient field points perpendicular

```

---

### 6. Matrix Calculus Identities

**Scalar-by-Vector:**

```
âˆ‚/âˆ‚x (aáµ€x) = a

âˆ‚/âˆ‚x (xáµ€Ax) = (A + Aáµ€)x
            = 2Ax  [if A symmetric]

âˆ‚/âˆ‚x ||x||Â² = 2x

âˆ‚/âˆ‚x ||Ax - b||Â² = 2Aáµ€(Ax - b)

```

**Proof (âˆ‚/âˆ‚x xáµ€Ax):**

```
Let f(x) = xáµ€Ax = Î£áµ¢â±¼ xáµ¢Aáµ¢â±¼xâ±¼

âˆ‚f/âˆ‚xâ‚– = âˆ‚/âˆ‚xâ‚– Î£áµ¢â±¼ xáµ¢Aáµ¢â±¼xâ±¼
       = Î£â±¼ Aâ‚–â±¼xâ±¼ + Î£áµ¢ xáµ¢Aáµ¢â‚–  [product rule]
       = (Ax)â‚– + (Aáµ€x)â‚–
       = [(A + Aáµ€)x]â‚–

Therefore: âˆ‡â‚“(xáµ€Ax) = (A + Aáµ€)x  âœ“

If A symmetric: = 2Ax

```

**Vector-by-Matrix:**

```
âˆ‚/âˆ‚W (Wx) = xáµ€ âŠ— I = xIáµ€
           (results in correct shape)

âˆ‚/âˆ‚W tr(WX) = Xáµ€

âˆ‚/âˆ‚W tr(Wáµ€AW) = A + Aáµ€)W
                = 2AW  [if A symmetric]

âˆ‚/âˆ‚W ||WX - Y||Â²_F = 2(WX - Y)Xáµ€

```

**Matrix-by-Matrix (Trace Formulation):**

```
For loss L involving matrix W:

âˆ‚L/âˆ‚W computed using:
  dL = tr((âˆ‚L/âˆ‚W)áµ€ dW)

Example: L = tr(Wáµ€AW)
  dL = tr((A + Aáµ€)W)áµ€ dW)
  
  Therefore: âˆ‚L/âˆ‚W = (A + Aáµ€)W

```

---

### 7. Automatic Differentiation: Forward vs Reverse Mode

**Forward Mode (Tangent Propagation):**

```
Compute derivatives along with values

For y = f(g(x)):
  Seed: áº‹ = 1 (derivative w.r.t. x)
  
  Forward:
    u = g(x),  uÌ‡ = g'(x)áº‹
    y = f(u),  áº = f'(u)uÌ‡
  
  Result: áº = dy/dx

Complexity: O(n) operations per input variable
Good for: Few inputs, many outputs (Jacobian rows)

```

**Reverse Mode (Backpropagation):**

```
Compute derivatives backward from output

For y = f(g(x)):
  Forward: Compute and store values
    u = g(x)
    y = f(u)
  
  Seed: È³ = 1 (derivative of y w.r.t. itself)
  
  Backward:
    Å« = È³ Â· f'(u)
    xÌ„ = Å« Â· g'(x)
  
  Result: xÌ„ = dy/dx

Complexity: O(1) operations per output variable
Good for: Many inputs, few outputs (gradient!)
  
This is why backprop is efficient for neural networks!
  Millions of parameters, single loss

```

**Comparison:**

```
Function: f: â„â¿ â†’ â„áµ

Forward Mode:
  One pass per input variable
  Total: n passes
  Computes: One column of Jacobian per pass
  Best: n << m

Reverse Mode:
  One pass per output variable
  Total: m passes
  Computes: One row of Jacobian per pass
  Best: m << n (like neural networks: m=1, n=millions)

```

**Example: Neural Network**

```
f: â„Â¹'â°â°â°'â°â°â° â†’ â„Â¹  (million params, scalar loss)

Forward mode: Need 1,000,000 passes  âœ—
Reverse mode: Need 1 pass          âœ“

This is the power of backpropagation!

```

---

### 8. Implicit Function Theorem

**Theorem:**

```
Let F(x, y) = 0 define y implicitly as function of x

If:
  1. F is CÂ¹
  2. F(xâ‚€, yâ‚€) = 0
  3. âˆ‚F/âˆ‚y(xâ‚€, yâ‚€) â‰  0

Then near (xâ‚€, yâ‚€), âˆƒ function y = g(x) such that:
  F(x, g(x)) = 0

Derivative:
  dy/dx = -(âˆ‚F/âˆ‚x) / (âˆ‚F/âˆ‚y)

```

**Proof:**

```
Differentiate F(x, y(x)) = 0 w.r.t. x:
  âˆ‚F/âˆ‚x + (âˆ‚F/âˆ‚y)(dy/dx) = 0

Solve for dy/dx:
  dy/dx = -(âˆ‚F/âˆ‚x) / (âˆ‚F/âˆ‚y)  âœ“

```

**Application: Constrained Optimization**

```
Minimize f(x) subject to g(x) = 0

At optimum, âˆ‡f parallel to âˆ‡g:
  âˆ‡f = Î»âˆ‡g  [Lagrange multipliers]

Implicit function theorem explains why:
  Constraint defines manifold
  Gradient perpendicular to feasible directions

```

---

### 9. Mean Value Theorem and Lipschitz Continuity

**Mean Value Theorem:**

```
If f: [a,b] â†’ â„ is continuous on [a,b] and differentiable on (a,b):
  âˆƒc âˆˆ (a,b) such that:
    f'(c) = (f(b) - f(a)) / (b - a)

Geometric: âˆƒ point where tangent parallel to chord

```

**Multivariable Version:**

```
For f: â„â¿ â†’ â„:
  f(x + h) - f(x) = âˆ‡f(x + th) Â· h  for some t âˆˆ [0,1]

Used extensively in convergence proofs!

```

**Lipschitz Continuity:**

```
f is L-Lipschitz if:
  ||f(x) - f(y)|| â‰¤ L||x - y||  for all x, y

L-smooth (differentiable version):
  ||âˆ‡f(x) - âˆ‡f(y)|| â‰¤ L||x - y||

Implications:
  â€¢ Bounded gradient: ||âˆ‡f(x)|| â‰¤ L||x|| + C
  â€¢ Predictable behavior
  â€¢ Convergence guarantees for optimization

```

**Application to Neural Networks:**

```
Activation functions:
  ReLU: 1-Lipschitz (gradient âˆˆ {0,1})
  Sigmoid: 0.25-Lipschitz (max gradient = 1/4)
  Tanh: 1-Lipschitz (max gradient = 1)

Network: f = f_L âˆ˜ ... âˆ˜ f_1

Lipschitz constant:
  L(f) â‰¤ L(f_L) Â· ... Â· L(f_1)
       â‰¤ ||W_L|| Â· ... Â· ||W_1||  [for linear layers]

This explains exploding/vanishing gradients!
  If ||W|| > 1: gradients explode
  If ||W|| < 1: gradients vanish

```

---

## ğŸ“‚ Topics in This Folder

| Folder | Topics | ML Application |
|--------|--------|----------------|
| [limits-continuity/](./limits-continuity/) | Limits, continuity | Convergence analysis |
| [derivatives/](./derivatives/) | Single, partial, higher-order | Gradient computation |
| [gradients/](./gradients/) | âˆ‡f, Jacobian, Hessian | ğŸ”¥ Core of ML training! |
| [chain-rule/](./chain-rule/) | Composition, backprop | ğŸ”¥ How neural nets learn! |
| [taylor/](./taylor/) | Series, approximations | Convergence rates |
| [integration/](./integration/) | Single, multiple, Monte Carlo | Expectation, sampling |

---

## ğŸ¯ Why Calculus is Essential for ML

```
Training a Neural Network:

1. Forward pass: compute Å· = f(x; Î¸)
2. Loss: L = loss(Å·, y)
3. Backward pass: âˆ‚L/âˆ‚Î¸ = ???    â† Need calculus!
4. Update: Î¸ â† Î¸ - Î± Â· âˆ‚L/âˆ‚Î¸    â† Gradient descent!

The entire deep learning revolution is built on:
â€¢ Chain rule â†’ Backpropagation
â€¢ Gradients â†’ Optimization
â€¢ Taylor â†’ Convergence analysis

```

---

## ğŸŒ ML Applications

| Concept | Application | Example |
|---------|-------------|---------|
| Gradient âˆ‡f | Parameter updates | SGD, Adam |
| Jacobian | Multi-output models | Normalizing flows |
| Hessian | Curvature | Newton's method, Fisher |
| Chain rule | Backpropagation | All deep learning |
| Taylor | Local approximation | Convergence proofs |
| Monte Carlo | Expected gradients | Variational inference |

---

## ğŸ”— Dependency Graph

```
limits-continuity/
        |
        v
    derivatives/
        |
        +--> gradients/     --> All ML optimization
        |         |
        |                                                               â–¼
        +--> chain-rule/    --> Backpropagation
                  |
                  v
             taylor/        --> Convergence analysis

```

---

## ğŸ”‘ Key Formulas

```
Gradient:      âˆ‡f = (âˆ‚f/âˆ‚xâ‚, âˆ‚f/âˆ‚xâ‚‚, ..., âˆ‚f/âˆ‚xâ‚™)áµ€

Jacobian:      J = [âˆ‚fáµ¢/âˆ‚xâ±¼]  (m Ã— n matrix)

Hessian:       H = [âˆ‚Â²f/âˆ‚xáµ¢âˆ‚xâ±¼]  (n Ã— n matrix)

Chain rule:    d/dx f(g(x)) = f'(g(x)) Â· g'(x)

Taylor (1st):  f(x + h) â‰ˆ f(x) + âˆ‡f(x)áµ€h

Taylor (2nd):  f(x + h) â‰ˆ f(x) + âˆ‡f(x)áµ€h + Â½háµ€H(x)h

```

---

## ğŸ“š Resources

| Type | Title | Link |
|------|-------|------|
| ğŸ“– | Calculus on Manifolds | Spivak |
| ğŸ¥ | Essence of Calculus | [3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) |
| ğŸ“– | Matrix Calculus for DL | [Paper](https://arxiv.org/abs/1802.01528) |

## ğŸ”— Where This Topic Is Used

| Application | Usage |
|-------------|-------|
| **Machine Learning** | Core concept for ML systems |
| **Deep Learning** | Foundation for neural networks |
| **Research** | Important for understanding papers |

---

â¬…ï¸ [Back: 01-Linear Algebra](../01_linear_algebra/) | â¡ï¸ [Next: 03-Optimization](../03_optimization/)

---

---

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=00C853&height=80&section=footer" width="100%"/>
</p>
