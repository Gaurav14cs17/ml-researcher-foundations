<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 2475.0 2025.0">
  <ns0:text x="550" y="30" font-size="22" font-weight="bold" text-anchor="middle" fill="#1a237e">
    Batch Normalization vs Layer Normalization: Complete Comparison
  </ns0:text>
  <ns0:g transform="translate(50, 80)">
    <ns0:text x="500" y="55.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#1565c0">
      1. Why Normalize Activations?
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="225.0" fill="#f8f9fa" stroke="#007bff" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="80.0" font-size="13" fill="#1a237e">
        â€¢ 
        <ns0:tspan font-weight="bold" fill="#1565c0">Internal Covariate Shift:</ns0:tspan>
        Distribution of layer inputs changes during training â†’ Slows learning
      </ns0:text>
      <ns0:text x="0" y="105.0" font-size="13" fill="#1a237e">
        â€¢ 
        <ns0:tspan font-weight="bold" fill="#1565c0">Solution:</ns0:tspan>
        Normalize activations â†’ Stable distributions â†’ Faster convergence, higher learning rates
      </ns0:text>
      <ns0:text x="0" y="130.0" font-size="13" fill="#1a237e">
        â€¢ 
        <ns0:tspan font-weight="bold" fill="#1565c0">Bonus:</ns0:tspan>
        Acts as regularization (adds noise), reduces sensitivity to initialization
      </ns0:text>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 220)">
    <ns0:text x="250" y="155.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#2e7d32">
      2. Batch Normalization
    </ns0:text>
    <ns0:rect x="0" y="20" width="500" height="340" fill="#1a237e" stroke="#28a745" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="180.0" font-size="14" font-weight="bold" fill="#145a32">
        Normalize across batch dimension
      </ns0:text>
      <ns0:g transform="translate(50, 30)">
        <ns0:text x="0" y="205.0" font-size="11" text-anchor="middle" fill="#1a237e">Batch â†’</ns0:text>
        <ns0:text x="-30" y="230.0" font-size="11" fill="#1a237e" transform="rotate(-90 -30 60)">
          Features â†“
        </ns0:text>
        <ns0:g>
          <ns0:rect x="0" y="0" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="0" y="30" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="0" y="60" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="0" y="90" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="35" y="0" width="25" height="120" fill="#2e7d32" opacity="0.6" stroke="#145a32" stroke-width="3"/>
          <ns0:text x="47" y="255.0" font-size="10" text-anchor="middle" fill="#2e7d32" font-weight="bold">
            Normalize this
          </ns0:text>
          <ns0:text x="47" y="280.0" font-size="10" text-anchor="middle" fill="#2e7d32" font-weight="bold">
            column
          </ns0:text>
        </ns0:g>
        <ns0:g transform="translate(180, 20)">
          <ns0:text x="0" y="305.0" font-size="12" fill="#1a237e">
            For each feature:
          </ns0:text>
          <ns0:text x="0" y="330.0" font-size="11" font-family="Arial, sans-serif" fill="#2e7d32">
            Î¼ = (1/N) Î£áµ¢ xáµ¢
          </ns0:text>
          <ns0:text x="0" y="355.0" font-size="11" font-family="Arial, sans-serif" fill="#2e7d32">
            ÏƒÂ² = (1/N) Î£áµ¢ (xáµ¢-Î¼)Â²
          </ns0:text>
          <ns0:text x="0" y="380.0" font-size="11" font-family="Arial, sans-serif" fill="#2e7d32">
            xÌ‚áµ¢ = (xáµ¢-Î¼) / âˆš(ÏƒÂ²+Îµ)
          </ns0:text>
          <ns0:text x="0" y="405.0" font-size="11" font-family="Arial, sans-serif" fill="#2e7d32">
            yáµ¢ = Î³xÌ‚áµ¢ + Î²
          </ns0:text>
        </ns0:g>
      </ns0:g>
      <ns0:g transform="translate(0, 200)">
        <ns0:text x="0" y="430.0" font-size="13" font-weight="bold" fill="#145a32">
          Advantages:
        </ns0:text>
        <ns0:text x="0" y="455.0" font-size="12" fill="#2e7d32">
          âœ“ Faster training (2-10x speedup)
        </ns0:text>
        <ns0:text x="0" y="480.0" font-size="12" fill="#2e7d32">
          âœ“ Higher learning rates possible
        </ns0:text>
        <ns0:text x="0" y="505.0" font-size="12" fill="#2e7d32">
          âœ“ Standard for CNNs
        </ns0:text>
        <ns0:text x="0" y="530.0" font-size="13" font-weight="bold" fill="#c62828">
          Disadvantages:
        </ns0:text>
        <ns0:text x="0" y="555.0" font-size="12" fill="#c62828">
          âœ— Batch size dependent (unstable for small batches)
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(580, 220)">
    <ns0:text x="235" y="580.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#6a1b9a">
      3. Layer Normalization
    </ns0:text>
    <ns0:rect x="0" y="20" width="470" height="340" fill="#1a237e" stroke="#6f42c1" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="605.0" font-size="14" font-weight="bold" fill="#6c3483">
        Normalize across feature dimension
      </ns0:text>
      <ns0:g transform="translate(50, 30)">
        <ns0:text x="0" y="630.0" font-size="11" text-anchor="middle" fill="#1a237e">Batch â†’</ns0:text>
        <ns0:text x="-30" y="655.0" font-size="11" fill="#1a237e" transform="rotate(-90 -30 60)">
          Features â†“
        </ns0:text>
        <ns0:g>
          <ns0:rect x="0" y="0" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="0" y="30" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="0" y="60" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="0" y="90" width="120" height="25" fill="#1565c0" opacity="0.3" stroke="#007bff" stroke-width="1"/>
          <ns0:rect x="0" y="45" width="120" height="25" fill="#6a1b9a" opacity="0.6" stroke="#6f42c1" stroke-width="3"/>
          <ns0:text x="60" y="680.0" font-size="10" text-anchor="middle" fill="#6a1b9a" font-weight="bold">
            Normalize this
          </ns0:text>
          <ns0:text x="60" y="705.0" font-size="10" text-anchor="middle" fill="#6a1b9a" font-weight="bold">
            row
          </ns0:text>
        </ns0:g>
        <ns0:g transform="translate(180, 20)">
          <ns0:text x="0" y="730.0" font-size="12" fill="#1a237e">
            For each sample:
          </ns0:text>
          <ns0:text x="0" y="755.0" font-size="11" font-family="Arial, sans-serif" fill="#6a1b9a">
            Î¼ = (1/D) Î£â±¼ xâ±¼
          </ns0:text>
          <ns0:text x="0" y="780.0" font-size="11" font-family="Arial, sans-serif" fill="#6a1b9a">
            ÏƒÂ² = (1/D) Î£â±¼ (xâ±¼-Î¼)Â²
          </ns0:text>
          <ns0:text x="0" y="805.0" font-size="11" font-family="Arial, sans-serif" fill="#6a1b9a">
            xÌ‚â±¼ = (xâ±¼-Î¼) / âˆš(ÏƒÂ²+Îµ)
          </ns0:text>
          <ns0:text x="0" y="830.0" font-size="11" font-family="Arial, sans-serif" fill="#6a1b9a">
            yâ±¼ = Î³xÌ‚â±¼ + Î²
          </ns0:text>
        </ns0:g>
      </ns0:g>
      <ns0:g transform="translate(0, 200)">
        <ns0:text x="0" y="855.0" font-size="13" font-weight="bold" fill="#6c3483">
          Advantages:
        </ns0:text>
        <ns0:text x="0" y="880.0" font-size="12" fill="#6a1b9a">
          âœ“ Batch size independent (works for batch=1!)
        </ns0:text>
        <ns0:text x="0" y="905.0" font-size="12" fill="#6a1b9a">
          âœ“ Standard for Transformers/RNNs
        </ns0:text>
        <ns0:text x="0" y="930.0" font-size="12" fill="#6a1b9a">
          âœ“ Same behavior in train &amp; inference
        </ns0:text>
        <ns0:text x="0" y="955.0" font-size="13" font-weight="bold" fill="#c62828">
          Disadvantages:
        </ns0:text>
        <ns0:text x="0" y="980.0" font-size="12" fill="#c62828">
          âœ— Slightly slower than BatchNorm for CNNs
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 600)">
    <ns0:text x="500" y="1005.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#e67e22">
      4. Quick Comparison
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="260" fill="#1a237e" stroke="#fd7e14" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:g>
        <ns0:text x="150" y="1030.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#1a237e">
          Aspect
        </ns0:text>
        <ns0:text x="400" y="1055.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#2e7d32">
          Batch Norm
        </ns0:text>
        <ns0:text x="700" y="1080.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#6a1b9a">
          Layer Norm
        </ns0:text>
      </ns0:g>
      <ns0:line x1="0" y1="12" x2="940" y2="12" stroke="#444444" stroke-width="2"/>
      <ns0:g transform="translate(0, 30)">
        <ns0:text x="20" y="1105.0" font-size="12" fill="#1a237e">Normalize over</ns0:text>
        <ns0:text x="400" y="1130.0" font-size="12" text-anchor="middle" fill="#2e7d32">Batch dimension</ns0:text>
        <ns0:text x="700" y="1155.0" font-size="12" text-anchor="middle" fill="#6a1b9a">Feature dimension</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 55)">
        <ns0:text x="20" y="1180.0" font-size="12" fill="#1a237e">Batch size dependency</ns0:text>
        <ns0:text x="400" y="1205.0" font-size="12" text-anchor="middle" fill="#c62828">Yes (requires large batches)</ns0:text>
        <ns0:text x="700" y="1230.0" font-size="12" text-anchor="middle" fill="#2e7d32">No (works for batch=1)</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 80)">
        <ns0:text x="20" y="1255.0" font-size="12" fill="#1a237e">Train vs Inference</ns0:text>
        <ns0:text x="400" y="1280.0" font-size="12" text-anchor="middle" fill="#c62828">Different (moving avg)</ns0:text>
        <ns0:text x="700" y="1305.0" font-size="12" text-anchor="middle" fill="#2e7d32">Same</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 105)">
        <ns0:text x="20" y="1330.0" font-size="12" fill="#1a237e">Best for</ns0:text>
        <ns0:text x="400" y="1355.0" font-size="12" text-anchor="middle" fill="#2e7d32">CNNs, large batches</ns0:text>
        <ns0:text x="700" y="1380.0" font-size="12" text-anchor="middle" fill="#2e7d32">Transformers, RNNs, small batches</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 130)">
        <ns0:text x="20" y="1405.0" font-size="12" fill="#1a237e">Learnable params</ns0:text>
        <ns0:text x="400" y="1430.0" font-size="12" text-anchor="middle" fill="#1a237e">Î³, Î² per feature</ns0:text>
        <ns0:text x="700" y="1455.0" font-size="12" text-anchor="middle" fill="#1a237e">Î³, Î² per feature</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 155)">
        <ns0:text x="20" y="1480.0" font-size="12" fill="#1a237e">Computational cost</ns0:text>
        <ns0:text x="400" y="1505.0" font-size="12" text-anchor="middle" fill="#2e7d32">Lower</ns0:text>
        <ns0:text x="700" y="1530.0" font-size="12" text-anchor="middle" fill="#1a237e">Slightly higher</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 190)">
        <ns0:rect x="0" y="0" width="940" height="40" fill="#e1f5fe" stroke="#007bff" stroke-width="1" rx="3"/>
        <ns0:text x="470" y="1555.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#1a5276">
          ðŸ’¡ Rule of thumb: BatchNorm for CNNs, LayerNorm for Transformers/RNNs
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
</ns0:svg>
