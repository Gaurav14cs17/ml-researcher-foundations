<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=45B7D1&height=120&section=header&text=Deep%20Learning%20Architectures&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-06-45B7D1?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## üéØ Visual Overview

This folder contains detailed visualizations of advanced deep learning architectures used in modern AI systems.

---

## üìÇ Topics

| Folder | Architecture | Key Application |
|--------|--------------|-----------------|
| [attention/](./attention/) | Attention Mechanisms | Transformers, NLP |
| [cnn/](./cnn/) | Convolutional Networks | Computer Vision |
| [diffusion/](./diffusion/) | Diffusion Models | Image Generation |
| [generative/](./generative/) | VAE, GAN | Generation |
| [gnn/](./gnn/) | Graph Neural Networks | Graph Data |
| [language-models/](./language-models/) | LLMs | GPT, BERT |
| [mixture-of-experts/](./mixture-of-experts/) | MoE | Scaling |
| [resnet/](./resnet/) | Residual Networks | Deep CNNs |
| [rnn/](./rnn/) | Recurrent Networks | Sequences |
| [seq2seq/](./seq2seq/) | Sequence-to-Sequence | Translation |
| [transformer/](./transformer/) | Transformer | Everything! |
| [vit/](./vit/) | Vision Transformer | Image Classification |

---

## üìê Architecture Evolution

```
Timeline:
1989: LeNet (CNN)
2012: AlexNet (Deep CNN)
2014: GoogLeNet (Inception)
2015: ResNet (Residual connections)
2017: Transformer (Attention is all you need)
2018: BERT (Pretrained transformers)
2020: GPT-3 (Large language models)
2021: Vision Transformer (ViT)
2022: Diffusion Models (Image generation)
2023: Mixture of Experts (Efficient scaling)

```

---

## üîó Where Architectures Are Used

| Architecture | Applications |
|--------------|--------------|
| **CNN** | Image classification, object detection |
| **Transformer** | NLP, vision, multimodal |
| **Diffusion** | Image/video generation |
| **GNN** | Social networks, molecules |
| **RNN/LSTM** | Time series, legacy NLP |

---

‚¨ÖÔ∏è [Back: Architectures](../03_architectures/README.md) | ‚û°Ô∏è [Next: Training](../04_training/README.md)

---

‚¨ÖÔ∏è [Back: Deep Learning](../README.md)

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=45B7D1&height=80&section=footer" width="100%"/>
</p>
