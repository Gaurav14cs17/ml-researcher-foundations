<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 2475.0 2025.0">
  <ns0:defs>
    <ns0:marker id="arrowGreen4" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <ns0:path d="M0,0 L0,6 L9,3 z" fill="#2e7d32"/>
    </ns0:marker>
    <ns0:marker id="arrowPurple3" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <ns0:path d="M0,0 L0,6 L9,3 z" fill="#6a1b9a"/>
    </ns0:marker>
  </ns0:defs>
  <ns0:text x="550" y="30" font-size="22" font-weight="bold" text-anchor="middle" fill="#1a237e">
    BERT vs GPT: Two Paradigms for Language Understanding
  </ns0:text>
  <ns0:g transform="translate(50, 80)">
    <ns0:text x="500" y="55.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#1565c0">
      1. Bidirectional vs Autoregressive
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="225.0" fill="#f8f9fa" stroke="#007bff" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="80.0" font-size="13" fill="#1a237e">
        <ns0:tspan font-weight="bold" fill="#2e7d32">BERT (Bidirectional Encoder):</ns0:tspan>
        Masked Language Modeling → Understands context from both directions → Best for understanding
      </ns0:text>
      <ns0:text x="0" y="105.0" font-size="13" fill="#1a237e">
        <ns0:tspan font-weight="bold" fill="#6a1b9a">GPT (Autoregressive Decoder):</ns0:tspan>
        Predict next token → Left-to-right only → Best for generation
      </ns0:text>
      <ns0:text x="0" y="130.0" font-size="12" fill="#1a237e">
        Both use Transformers, but different training objectives and architectures!
      </ns0:text>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 220)">
    <ns0:text x="250" y="155.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#2e7d32">
      2. BERT: Masked Language Modeling
    </ns0:text>
    <ns0:rect x="0" y="20" width="500" height="320" fill="#1a237e" stroke="#28a745" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="180.0" font-size="13" font-weight="bold" fill="#145a32">
        Training Objective:
      </ns0:text>
      <ns0:g transform="translate(20, 25)">
        <ns0:text x="0" y="205.0" font-size="12" fill="#1a237e">
          Input: &quot;The cat [MASK] on the mat&quot;
        </ns0:text>
        <ns0:text x="0" y="230.0" font-size="12" fill="#2e7d32" font-weight="bold">
          Predict: &quot;sat&quot; (using both left AND right context)
        </ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 65)">
        <ns0:text x="0" y="255.0" font-size="12" font-weight="bold" fill="#145a32">
          Architecture:
        </ns0:text>
        <ns0:g transform="translate(30, 20)">
          <ns0:rect x="0" y="0" width="50" height="30" fill="#1565c0" opacity="0.7" stroke="#007bff" stroke-width="2" rx="3"/>
          <ns0:text x="25" y="280.0" font-size="10" text-anchor="middle" fill="#1a237e">The</ns0:text>
          <ns0:rect x="60" y="0" width="50" height="30" fill="#1565c0" opacity="0.7" stroke="#007bff" stroke-width="2" rx="3"/>
          <ns0:text x="85" y="305.0" font-size="10" text-anchor="middle" fill="#1a237e">cat</ns0:text>
          <ns0:rect x="120" y="0" width="60" height="30" fill="#c62828" opacity="0.7" stroke="#dc3545" stroke-width="2" rx="3"/>
          <ns0:text x="150" y="330.0" font-size="10" text-anchor="middle" fill="#1a237e">[MASK]</ns0:text>
          <ns0:rect x="190" y="0" width="50" height="30" fill="#1565c0" opacity="0.7" stroke="#007bff" stroke-width="2" rx="3"/>
          <ns0:text x="215" y="355.0" font-size="10" text-anchor="middle" fill="#1a237e">on</ns0:text>
          <ns0:path d="M 150,40 L 25,70" stroke="#28a745" stroke-width="2" marker-end="url(#arrowGreen4)"/>
          <ns0:path d="M 25,70 L 150,40" stroke="#28a745" stroke-width="2" stroke-dasharray="3,3"/>
          <ns0:path d="M 150,40 L 215,70" stroke="#28a745" stroke-width="2" marker-end="url(#arrowGreen4)"/>
          <ns0:path d="M 215,70 L 150,40" stroke="#28a745" stroke-width="2" stroke-dasharray="3,3"/>
          <ns0:text x="120" y="380.0" font-size="10" text-anchor="middle" fill="#2e7d32" font-weight="bold">
            Bidirectional attention
          </ns0:text>
        </ns0:g>
      </ns0:g>
      <ns0:g transform="translate(0, 190)">
        <ns0:text x="0" y="405.0" font-size="12" font-weight="bold" fill="#145a32">
          Key Points:
        </ns0:text>
        <ns0:text x="0" y="430.0" font-size="11" fill="#1a237e">
          • Encoder-only architecture (12-24 layers)
        </ns0:text>
        <ns0:text x="0" y="455.0" font-size="11" fill="#1a237e">
          • Mask 15% of tokens during training
        </ns0:text>
        <ns0:text x="0" y="480.0" font-size="11" fill="#2e7d32" font-weight="bold">
          ✓ Best for: Classification, QA, NER, sentiment
        </ns0:text>
        <ns0:text x="0" y="505.0" font-size="11" fill="#c62828">
          ✗ Cannot generate text (no autoregressive)
        </ns0:text>
        <ns0:text x="0" y="530.0" font-size="11" fill="#1a237e">
          Examples: BERT, RoBERTa, ALBERT, DeBERTa
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(580, 220)">
    <ns0:text x="235" y="555.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#6a1b9a">
      3. GPT: Next Token Prediction
    </ns0:text>
    <ns0:rect x="0" y="20" width="470" height="320" fill="#1a237e" stroke="#6f42c1" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="580.0" font-size="13" font-weight="bold" fill="#6c3483">
        Training Objective:
      </ns0:text>
      <ns0:g transform="translate(20, 25)">
        <ns0:text x="0" y="605.0" font-size="12" fill="#1a237e">
          Input: &quot;The cat sat on the&quot;
        </ns0:text>
        <ns0:text x="0" y="630.0" font-size="12" fill="#6a1b9a" font-weight="bold">
          Predict: &quot;mat&quot; (using ONLY left context)
        </ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 65)">
        <ns0:text x="0" y="655.0" font-size="12" font-weight="bold" fill="#6c3483">
          Architecture:
        </ns0:text>
        <ns0:g transform="translate(30, 20)">
          <ns0:rect x="0" y="0" width="50" height="30" fill="#1565c0" opacity="0.7" stroke="#007bff" stroke-width="2" rx="3"/>
          <ns0:text x="25" y="680.0" font-size="10" text-anchor="middle" fill="#1a237e">The</ns0:text>
          <ns0:rect x="60" y="0" width="50" height="30" fill="#1565c0" opacity="0.7" stroke="#007bff" stroke-width="2" rx="3"/>
          <ns0:text x="85" y="705.0" font-size="10" text-anchor="middle" fill="#1a237e">cat</ns0:text>
          <ns0:rect x="120" y="0" width="50" height="30" fill="#1565c0" opacity="0.7" stroke="#007bff" stroke-width="2" rx="3"/>
          <ns0:text x="145" y="730.0" font-size="10" text-anchor="middle" fill="#1a237e">sat</ns0:text>
          <ns0:rect x="180" y="0" width="50" height="30" fill="#e65100" opacity="0.7" stroke="#e67e22" stroke-width="3" rx="3"/>
          <ns0:text x="205" y="755.0" font-size="10" text-anchor="middle" fill="#1a237e">?</ns0:text>
          <ns0:path d="M 25,40 L 205,70" stroke="#6f42c1" stroke-width="2" marker-end="url(#arrowPurple3)"/>
          <ns0:path d="M 85,40 L 205,70" stroke="#6f42c1" stroke-width="2" marker-end="url(#arrowPurple3)"/>
          <ns0:path d="M 145,40 L 205,70" stroke="#6f42c1" stroke-width="2" marker-end="url(#arrowPurple3)"/>
          <ns0:text x="115" y="780.0" font-size="10" text-anchor="middle" fill="#6a1b9a" font-weight="bold">
            Causal (left-to-right) attention
          </ns0:text>
        </ns0:g>
      </ns0:g>
      <ns0:g transform="translate(0, 190)">
        <ns0:text x="0" y="805.0" font-size="12" font-weight="bold" fill="#6c3483">
          Key Points:
        </ns0:text>
        <ns0:text x="0" y="830.0" font-size="11" fill="#1a237e">
          • Decoder-only architecture (12-96+ layers)
        </ns0:text>
        <ns0:text x="0" y="855.0" font-size="11" fill="#1a237e">
          • Predict next token given all previous tokens
        </ns0:text>
        <ns0:text x="0" y="880.0" font-size="11" fill="#2e7d32" font-weight="bold">
          ✓ Best for: Generation, completion, chat
        </ns0:text>
        <ns0:text x="0" y="905.0" font-size="11" fill="#2e7d32">
          ✓ Zero-shot, few-shot learning (in-context)
        </ns0:text>
        <ns0:text x="0" y="930.0" font-size="11" fill="#1a237e">
          Examples: GPT-3, GPT-4, LLaMA, Mistral
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 580)">
    <ns0:text x="500" y="955.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#e67e22">
      4. Quick Comparison
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="240" fill="#1a237e" stroke="#fd7e14" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="200" y="980.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#2e7d32">BERT</ns0:text>
      <ns0:text x="500" y="1005.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#1a237e">Aspect</ns0:text>
      <ns0:text x="800" y="1030.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#6a1b9a">GPT</ns0:text>
      <ns0:line x1="0" y1="15" x2="940" y2="15" stroke="#444444" stroke-width="2"/>
      <ns0:g transform="translate(0, 35)">
        <ns0:text x="200" y="1055.0" font-size="11" text-anchor="middle" fill="#2e7d32">Bidirectional</ns0:text>
        <ns0:text x="500" y="1080.0" font-size="11" text-anchor="middle" fill="#1a237e" font-weight="bold">Attention</ns0:text>
        <ns0:text x="800" y="1105.0" font-size="11" text-anchor="middle" fill="#6a1b9a">Unidirectional (causal)</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 60)">
        <ns0:text x="200" y="1130.0" font-size="11" text-anchor="middle" fill="#2e7d32">Masked LM</ns0:text>
        <ns0:text x="500" y="1155.0" font-size="11" text-anchor="middle" fill="#1a237e" font-weight="bold">Training</ns0:text>
        <ns0:text x="800" y="1180.0" font-size="11" text-anchor="middle" fill="#6a1b9a">Next token prediction</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 85)">
        <ns0:text x="200" y="1205.0" font-size="11" text-anchor="middle" fill="#2e7d32">Encoder-only</ns0:text>
        <ns0:text x="500" y="1230.0" font-size="11" text-anchor="middle" fill="#1a237e" font-weight="bold">Architecture</ns0:text>
        <ns0:text x="800" y="1255.0" font-size="11" text-anchor="middle" fill="#6a1b9a">Decoder-only</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 110)">
        <ns0:text x="200" y="1280.0" font-size="11" text-anchor="middle" fill="#2e7d32">Understanding tasks</ns0:text>
        <ns0:text x="500" y="1305.0" font-size="11" text-anchor="middle" fill="#1a237e" font-weight="bold">Best Use</ns0:text>
        <ns0:text x="800" y="1330.0" font-size="11" text-anchor="middle" fill="#6a1b9a">Generation tasks</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 135)">
        <ns0:text x="200" y="1355.0" font-size="11" text-anchor="middle" fill="#2e7d32">Fine-tuning required</ns0:text>
        <ns0:text x="500" y="1380.0" font-size="11" text-anchor="middle" fill="#1a237e" font-weight="bold">Adaptation</ns0:text>
        <ns0:text x="800" y="1405.0" font-size="11" text-anchor="middle" fill="#6a1b9a">Few-shot prompting</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 160)">
        <ns0:text x="200" y="1430.0" font-size="11" text-anchor="middle" fill="#2e7d32">110M - 340M</ns0:text>
        <ns0:text x="500" y="1455.0" font-size="11" text-anchor="middle" fill="#1a237e" font-weight="bold">Typical Size</ns0:text>
        <ns0:text x="800" y="1480.0" font-size="11" text-anchor="middle" fill="#6a1b9a">1B - 175B+</ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:rect x="50" y="850" width="2250.0" height="40" fill="#e1f5fe" stroke="#007bff" stroke-width="2" rx="8"/>
  <ns0:text x="550" y="1505.0" font-size="13" text-anchor="middle" fill="#1a5276">
    <ns0:tspan font-weight="bold">Modern Trend:</ns0:tspan>
     Decoder-only (GPT-style) dominates due to better scaling &amp; in-context learning
  </ns0:text>
</ns0:svg>
