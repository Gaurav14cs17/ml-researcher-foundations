<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 2250.0 1687.5">
  <ns0:defs>
    <ns0:marker id="arrow" markerWidth="10" markerHeight="10" refX="8" refY="3" orient="auto">
      <ns0:path d="M0,0 L0,6 L9,3 z" fill="#1a237e"/>
    </ns0:marker>
  </ns0:defs>
  <ns0:rect width="2250.0" height="1687.5" fill="#f8f9fa" rx="8"/>
  <ns0:text x="500" y="30" font-family="Arial, sans-serif" font-size="26" font-weight="bold" text-anchor="middle" fill="#1a237e">
    Self-Attention Mechanism
  </ns0:text>
  <ns0:text x="500" y="55" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#1a237e" font-style="italic">
    The Core of Transformers: &quot;Attention is All You Need&quot;
  </ns0:text>
  <ns0:rect x="150" y="75" width="700" height="50" fill="#1a237e" stroke="#007bff" stroke-width="3" rx="8"/>
  <ns0:text x="500" y="108" font-family="Arial, sans-serif" font-size="20" text-anchor="middle" fill="#1a237e" font-weight="bold">
    Attention(Q, K, V) = softmax(QKᵀ/√dₖ)V
  </ns0:text>
  <ns0:g id="qkv">
    <ns0:text x="150" y="170" font-family="Arial, sans-serif" font-size="16" font-weight="bold" fill="#1565c0">
      Step 1: Compute Q, K, V
    </ns0:text>
    <ns0:rect x="100" y="190" width="120" height="60" fill="#6a1b9a" stroke="#6f42c1" stroke-width="2" rx="5"/>
    <ns0:text x="160" y="210" font-family="Arial, sans-serif" font-size="12" text-anchor="middle" fill="#1a237e" font-weight="bold">
      Input X
    </ns0:text>
    <ns0:text x="160" y="230" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="#1a237e">
      (n × d_model)
    </ns0:text>
    <ns0:line x1="160" y1="250" x2="160" y2="290" stroke="#e0e0e0" stroke-width="2"/>
    <ns0:line x1="160" y1="290" x2="100" y2="320" stroke="#e0e0e0" stroke-width="2"/>
    <ns0:line x1="160" y1="290" x2="160" y2="320" stroke="#e0e0e0" stroke-width="2"/>
    <ns0:line x1="160" y1="290" x2="220" y2="320" stroke="#e0e0e0" stroke-width="2"/>
    <ns0:rect x="60" y="320" width="80" height="60" fill="#c62828" stroke="#dc3545" stroke-width="2" rx="5"/>
    <ns0:text x="100" y="343" font-family="Arial, sans-serif" font-size="13" text-anchor="middle" fill="#1a237e" font-weight="bold">
      Query (Q)
    </ns0:text>
    <ns0:text x="100" y="365" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#1a237e">
      = X·Wᵠ
    </ns0:text>
    <ns0:rect x="150" y="320" width="80" height="60" fill="#e65100" stroke="#fd7e14" stroke-width="2" rx="5"/>
    <ns0:text x="190" y="390.0" font-family="Arial, sans-serif" font-size="13" text-anchor="middle" fill="#1a237e" font-weight="bold">
      Key (K)
    </ns0:text>
    <ns0:text x="190" y="415.0" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#1a237e">
      = X·Wᴷ
    </ns0:text>
    <ns0:rect x="240" y="320" width="80" height="60" fill="#2e7d32" stroke="#28a745" stroke-width="2" rx="5"/>
    <ns0:text x="280" y="440.0" font-family="Arial, sans-serif" font-size="13" text-anchor="middle" fill="#1a237e" font-weight="bold">
      Value (V)
    </ns0:text>
    <ns0:text x="280" y="465.0" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#1a237e">
      = X·Wⱽ
    </ns0:text>
  </ns0:g>
  <ns0:g id="scores">
    <ns0:text x="500" y="490.0" font-family="Arial, sans-serif" font-size="16" font-weight="bold" fill="#1565c0">
      Step 2: Compute Attention Scores
    </ns0:text>
    <ns0:rect x="420" y="200" width="160" height="50" fill="#1a237e" stroke="#dc3545" stroke-width="2" rx="5"/>
    <ns0:text x="500" y="515.0" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#1a237e" font-weight="bold">
      QKᵀ/√dₖ
    </ns0:text>
    <ns0:line x1="500" y1="250" x2="500" y2="280" stroke="#e0e0e0" stroke-width="2" marker-end="url(#arrow)"/>
    <ns0:text x="520" y="540.0" font-family="Arial, sans-serif" font-size="12" fill="#1565c0">softmax</ns0:text>
    <ns0:rect x="420" y="290" width="160" height="90" fill="#fff5e6" stroke="#fd7e14" stroke-width="3" rx="5"/>
    <ns0:text x="500" y="565.0" font-family="Arial, sans-serif" font-size="13" text-anchor="middle" fill="#e65100" font-weight="bold">
      Attention Weights
    </ns0:text>
    <ns0:text x="500" y="590.0" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="#1a237e">
      (n × n matrix)
    </ns0:text>
    <ns0:text x="500" y="615.0" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#1a237e" font-style="italic">
      Each row sums to 1
    </ns0:text>
  </ns0:g>
  <ns0:g id="weighted-sum">
    <ns0:text x="750" y="640.0" font-family="Arial, sans-serif" font-size="16" font-weight="bold" fill="#1565c0">
      Step 3: Weighted Sum
    </ns0:text>
    <ns0:rect x="670" y="200" width="160" height="50" fill="#1a237e" stroke="#28a745" stroke-width="2" rx="5"/>
    <ns0:text x="750" y="665.0" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#1a237e" font-weight="bold">
      Attention × V
    </ns0:text>
    <ns0:line x1="750" y1="250" x2="750" y2="280" stroke="#e0e0e0" stroke-width="2" marker-end="url(#arrow)"/>
    <ns0:rect x="670" y="290" width="160" height="90" fill="#d5f4e6" stroke="#28a745" stroke-width="3" rx="5"/>
    <ns0:text x="750" y="690.0" font-family="Arial, sans-serif" font-size="13" text-anchor="middle" fill="#2e7d32" font-weight="bold">
      Output
    </ns0:text>
    <ns0:text x="750" y="715.0" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="#1a237e">
      (n × d_model)
    </ns0:text>
    <ns0:text x="750" y="740.0" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#1a237e" font-style="italic">
      Context-aware features
    </ns0:text>
  </ns0:g>
  <ns0:rect x="50" y="420" width="900" height="300" fill="#1a237e" stroke="#007bff" stroke-width="3" rx="10"/>
  <ns0:text x="500" y="765.0" font-family="Arial, sans-serif" font-size="18" font-weight="bold" text-anchor="middle" fill="#1565c0">
    Example: &quot;The animal didn't cross the street because it was too tired&quot;
  </ns0:text>
  <ns0:g id="attention-viz">
    <ns0:text x="100" y="790.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">The</ns0:text>
    <ns0:text x="170" y="815.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">animal</ns0:text>
    <ns0:text x="250" y="840.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">didn't</ns0:text>
    <ns0:text x="320" y="865.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">cross</ns0:text>
    <ns0:text x="390" y="890.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">the</ns0:text>
    <ns0:text x="450" y="915.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">street</ns0:text>
    <ns0:text x="520" y="940.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">because</ns0:text>
    <ns0:text x="610" y="965.0" font-family="Arial, sans-serif" font-size="12" fill="#c62828" font-weight="bold">it</ns0:text>
    <ns0:text x="660" y="990.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">was</ns0:text>
    <ns0:text x="720" y="1015.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">too</ns0:text>
    <ns0:text x="780" y="1040.0" font-family="Arial, sans-serif" font-size="12" fill="#1a237e">tired</ns0:text>
    <ns0:line x1="630" y1="510" x2="190" y2="540" stroke="#dc3545" stroke-width="8" opacity="0.6"/>
    <ns0:text x="200" y="1065.0" font-family="Arial, sans-serif" font-size="11" fill="#c62828" font-weight="bold">0.7</ns0:text>
    <ns0:line x1="630" y1="510" x2="470" y2="540" stroke="#fd7e14" stroke-width="4" opacity="0.4"/>
    <ns0:text x="475" y="1090.0" font-family="Arial, sans-serif" font-size="11" fill="#e65100">0.2</ns0:text>
    <ns0:line x1="630" y1="510" x2="800" y2="540" stroke="#28a745" stroke-width="2" opacity="0.3"/>
    <ns0:text x="805" y="1115.0" font-family="Arial, sans-serif" font-size="11" fill="#2e7d32">0.1</ns0:text>
    <ns0:text x="500" y="1140.0" font-family="Arial, sans-serif" font-size="13" text-anchor="middle" fill="#1a237e">
      Attention weights show that &quot;it&quot; refers to &quot;animal&quot; (0.7), not &quot;street&quot; (0.2)
    </ns0:text>
  </ns0:g>
  <ns0:rect x="70" y="630" width="860" height="75" fill="#1a237e" rx="5"/>
  <ns0:text x="80" y="1165.0" font-family="Arial, sans-serif" font-size="13" fill="#1a237e">
    <ns0:tspan x="80" dy="0" font-weight="bold" fill="#1565c0">Key Properties:</ns0:tspan>
    <ns0:tspan x="90" dy="20">• Each token can attend to all other tokens (self-attention)</ns0:tspan>
    <ns0:tspan x="90" dy="18">• Attention weights learned during training via QKV projections</ns0:tspan>
    <ns0:tspan x="90" dy="18">• O(n²) complexity in sequence length - this is why Flash Attention matters!</ns0:tspan>
  </ns0:text>
</ns0:svg>