<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=45B7D1&height=120&section=header&text=Architectures&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-06-45B7D1?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## ğŸ¯ Visual Overview

<img src="./images/architecture-comparison.svg" width="100%">

*Caption: Evolution of neural network architectures from simple MLPs to modern Transformers and Diffusion models. Transformers (2017) revolutionized NLP and now dominate most domains. Diffusion models (2020) lead image generation.*

---

## ğŸ“ Mathematical Foundations

### MLP (Multi-Layer Perceptron)

```
y = Wâ‚™Ïƒ(Wâ‚™â‚‹â‚Ïƒ(...Ïƒ(Wâ‚x + bâ‚)...) + bâ‚™â‚‹â‚) + bâ‚™

Parameters: Î£áµ¢ dáµ¢ Ã— dáµ¢â‚Šâ‚ + dáµ¢â‚Šâ‚

```

### CNN (Convolutional Neural Network)

```
Convolution:
(f * g)(x) = Î£â‚– f(k) g(x - k)

2D Image:
yáµ¢â±¼ = Î£â‚˜ Î£â‚™ Wâ‚˜â‚™ xáµ¢â‚Šâ‚˜,â±¼â‚Šâ‚™ + b

Output size: (W - K + 2P) / S + 1

```

### Transformer Self-Attention

```
Attention(Q, K, V) = softmax(QKáµ€ / âˆšdâ‚–) V

Multi-head:
MultiHead = Concat(headâ‚, ..., headâ‚•) Wá´¼
headáµ¢ = Attention(XWáµ¢á´½, XWáµ¢á´·, XWáµ¢â±½)

```

### Diffusion Forward/Reverse

```
Forward (add noise):
q(xâ‚œ|xâ‚œâ‚‹â‚) = N(xâ‚œ; âˆš(1-Î²â‚œ)xâ‚œâ‚‹â‚, Î²â‚œI)

Reverse (denoise):
p_Î¸(xâ‚œâ‚‹â‚|xâ‚œ) = N(xâ‚œâ‚‹â‚; Î¼_Î¸(xâ‚œ, t), Î£_Î¸(xâ‚œ, t))

```

---

## ğŸ“‚ Topics

| Folder | Topic | Best For |
|--------|-------|----------|
| [mlp/](./mlp/) | Multi-layer perceptron | Tabular data |
| [cnn/](./cnn/) | Convolutional networks | Images |
| [rnn/](./rnn/) | Recurrent networks | Sequences |
| [transformer/](./transformer/) | ğŸ”¥ Attention | Everything! |
| [diffusion/](./diffusion/) | ğŸ”¥ Diffusion models | Generation |
| [moe/](./moe/) | Mixture of Experts | Scaling |

---

## ğŸ“Š Architecture Timeline

```
1980s: MLP
1990s: CNN (LeNet)
2010s: Deep CNN (AlexNet, ResNet)
2014:  GAN
2015:  LSTM/GRU for NLP
2017:  ğŸ”¥ Transformer
2020:  ViT (Vision Transformer)
2020:  ğŸ”¥ Diffusion Models
2022:  ğŸ”¥ MoE (Mixtral)

```

---

## ğŸ”‘ Choosing Architecture

| Data Type | Architecture |
|-----------|-------------|
| Images | CNN or ViT |
| Text | Transformer |
| Sequences | Transformer (or RNN) |
| Generation | Diffusion, GAN |
| Tabular | MLP, Gradient Boosting |

---

## ğŸ”— Where Each Architecture Is Used

| Architecture | Used In These Topics/Models |
|-------------|----------------------------|
| **Transformer** | GPT, BERT, LLaMA, ViT, Whisper, CLIP, Stable Diffusion (cross-attention) |
| **CNN** | ResNet, YOLO, U-Net (diffusion), Image encoders in CLIP |
| **RNN/LSTM** | Seq2seq (older), Time series, Speech (older) |
| **Diffusion** | Stable Diffusion, DALL-E, Imagen, Video generation |
| **MoE** | Mixtral, Switch Transformer, GShard |
| **GAN** | StyleGAN, Image editing (older approach) |

### Architecture Dependencies

```
Neural Network Basics
    +--> MLP (simplest)
    +--> CNN --> ResNet --> U-Net (diffusion)
    +--> RNN --> LSTM --> (mostly replaced by Transformer)
    +--> Transformer --> GPT, BERT, ViT
                    --> Cross-attention in Diffusion
                    --> MoE (Transformer + routing)

```

### Which Architecture For Which Task

| Task | Architecture | Why |
|------|--------------|-----|
| Text generation | Transformer (decoder) | Long-range dependencies |
| Image classification | CNN or ViT | Spatial structure |
| Image generation | Diffusion + U-Net | State-of-art quality |
| Speech recognition | Transformer | Whisper architecture |
| Efficient scaling | MoE | Sparse activation |

---

## ğŸ“š References

| Type | Title | Link |
|------|-------|------|
| ğŸ“„ | Attention Is All You Need | [arXiv](https://arxiv.org/abs/1706.03762) |
| ğŸ“„ | ResNet Paper | [arXiv](https://arxiv.org/abs/1512.03385) |
| ğŸ“– | Deep Learning Book | [Book](https://www.deeplearningbook.org/) |
| ğŸ‡¨ğŸ‡³ | æ·±åº¦å­¦ä¹ æ¶æ„æ€»ç»“ | [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/54356280) |
| ğŸ‡¨ğŸ‡³ | ç½‘ç»œæ¶æ„æ¼”è¿› | [CSDN](https://blog.csdn.net/qq_37466121/article/details/88619088) |
| ğŸ‡¨ğŸ‡³ | æ¶æ„å¯¹æ¯”è®²è§£ | [Bç«™](https://www.bilibili.com/video/BV1J94y1f7u5) |

---

â¬…ï¸ [Back: Backpropagation](../02_backpropagation/README.md) | â¡ï¸ [Next: Training](../04_training/README.md)

---

â¬…ï¸ [Back: Deep Learning](../README.md)

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=45B7D1&height=80&section=footer" width="100%"/>
</p>
