<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 2475.0 2025.0">
  <ns0:text x="550" y="30" font-size="22" font-weight="bold" text-anchor="middle" fill="#1a237e">
    Continual Learning: Learning New Tasks Without Forgetting
  </ns0:text>
  <ns0:g transform="translate(50, 80)">
    <ns0:text x="500" y="55.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#1565c0">
      1. What is Continual Learning?
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="315.0" fill="#f8f9fa" stroke="#007bff" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="80.0" font-size="14" fill="#1a237e">
        <ns0:tspan font-weight="bold" fill="#1565c0">Goal:</ns0:tspan>
        Learn sequence of tasks T‚ÇÅ, T‚ÇÇ, T‚ÇÉ, ... while retaining performance on all previous tasks
      </ns0:text>
      <ns0:g transform="translate(0, 30)">
        <ns0:text x="0" y="105.0" font-size="13" fill="#1a237e">
          <ns0:tspan font-weight="bold" fill="#c62828">Naive Fine-tuning:</ns0:tspan>
          Train on T‚ÇÅ ‚Üí Train on T‚ÇÇ ‚Üí Forget T‚ÇÅ! (Catastrophic forgetting)
        </ns0:text>
        <ns0:text x="0" y="130.0" font-size="13" fill="#2e7d32" font-weight="bold">
          <ns0:tspan fill="#145a32">Continual Learning:</ns0:tspan>
          Accumulate knowledge across tasks ‚Üí Maintain performance on all tasks
        </ns0:text>
        <ns0:text x="0" y="155.0" font-size="12" fill="#1a237e">
          Also called: Lifelong learning, incremental learning
        </ns0:text>
        <ns0:text x="0" y="180.0" font-size="12" fill="#1a237e">
          <ns0:tspan x="0" dy="0">Applications: Robots learning new skills, personalized</ns0:tspan>
          <ns0:tspan x="0" dy="1.2em">assistants, online learning systems</ns0:tspan>
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 260)">
    <ns0:text x="500" y="205.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#c62828">
      2. Catastrophic Forgetting Problem
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="200" fill="#1a237e" stroke="#dc3545" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(50, 60)">
      <ns0:g>
        <ns0:line x1="0" y1="120" x2="300" y2="120" stroke="#ffffff" stroke-width="2"/>
        <ns0:line x1="0" y1="0" x2="0" y2="125" stroke="#ffffff" stroke-width="2"/>
        <ns0:line x1="0" y1="30" x2="300" y2="30" stroke="#444444" stroke-width="1" stroke-dasharray="2,2" opacity="0.3"/>
        <ns0:line x1="0" y1="60" x2="300" y2="60" stroke="#444444" stroke-width="1" stroke-dasharray="2,2" opacity="0.3"/>
        <ns0:line x1="0" y1="90" x2="300" y2="90" stroke="#444444" stroke-width="1" stroke-dasharray="2,2" opacity="0.3"/>
        <ns0:line x1="100" y1="0" x2="100" y2="120" stroke="#444444" stroke-width="1" stroke-dasharray="2,2" opacity="0.3"/>
        <ns0:line x1="200" y1="0" x2="200" y2="120" stroke="#444444" stroke-width="1" stroke-dasharray="2,2" opacity="0.3"/>
        <ns0:path d="M 0,120 L 100,20" stroke="#28a745" stroke-width="4"/>
        <ns0:path d="M 100,20 L 200,100" stroke="#dc3545" stroke-width="4" stroke-dasharray="5,5"/>
        <ns0:text x="50" y="230.0" font-size="11" fill="#2e7d32" font-weight="bold">Task 1 learned</ns0:text>
        <ns0:text x="150" y="255.0" font-size="11" fill="#c62828" font-weight="bold">Forgotten!</ns0:text>
        <ns0:path d="M 100,120 L 200,30" stroke="#007bff" stroke-width="4"/>
        <ns0:text x="150" y="280.0" font-size="11" fill="#1565c0" font-weight="bold">Task 2 learned</ns0:text>
        <ns0:text x="150" y="305.0" font-size="12" text-anchor="middle" fill="#1a237e">Training Progress</ns0:text>
        <ns0:text x="-15" y="330.0" font-size="12" fill="#1a237e" transform="rotate(-90 -15 60)">
          Accuracy
        </ns0:text>
        <ns0:text x="50" y="355.0" font-size="10" text-anchor="middle" fill="#1a237e">Train T‚ÇÅ</ns0:text>
        <ns0:text x="150" y="380.0" font-size="10" text-anchor="middle" fill="#1a237e">Train T‚ÇÇ</ns0:text>
      </ns0:g>
      <ns0:g transform="translate(350, 20)">
        <ns0:text x="0" y="405.0" font-size="13" font-weight="bold" fill="#c62828">
          Why does this happen?
        </ns0:text>
        <ns0:g transform="translate(0, 25)">
          <ns0:text x="0" y="430.0" font-size="12" fill="#1a237e">
            ‚Ä¢ Weights optimized for T‚ÇÅ get
          </ns0:text>
          <ns0:text x="5" y="455.0" font-size="12" fill="#1a237e">
            overwritten when training on T‚ÇÇ
          </ns0:text>
        </ns0:g>
        <ns0:g transform="translate(0, 55)">
          <ns0:text x="0" y="480.0" font-size="12" fill="#1a237e">
            ‚Ä¢ Neural networks lack mechanisms
          </ns0:text>
          <ns0:text x="5" y="505.0" font-size="12" fill="#1a237e">
            to protect important weights
          </ns0:text>
        </ns0:g>
        <ns0:g transform="translate(0, 85)">
          <ns0:text x="0" y="530.0" font-size="12" fill="#1a237e">
            Human brain doesn't have this
          </ns0:text>
          <ns0:text x="0" y="555.0" font-size="12" fill="#1a237e">
            problem ‚Üí Inspiration for solutions!
          </ns0:text>
        </ns0:g>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 500)">
    <ns0:text x="500" y="580.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#2e7d32">
      3. Three Main Approaches
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="260" fill="#1a237e" stroke="#28a745" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:g>
        <ns0:text x="0" y="605.0" font-size="13" font-weight="bold" fill="#145a32">
          A. Regularization-Based: Protect important weights
        </ns0:text>
        <ns0:rect x="0" y="10" width="940" height="60" fill="#1a237e" stroke="#28a745" stroke-width="2" rx="3"/>
        <ns0:g transform="translate(15, 28)">
          <ns0:text x="0" y="630.0" font-size="12" fill="#1a237e">
            <ns0:tspan font-weight="bold" fill="#145a32">EWC (Elastic Weight Consolidation):</ns0:tspan>
            Add penalty for changing important weights:
          </ns0:text>
          <ns0:text x="20" y="655.0" font-size="11" font-family="Arial, sans-serif" fill="#2e7d32">
            L = L_task + Œª Œ£·µ¢ F·µ¢(Œ∏·µ¢ - Œ∏*·µ¢)¬≤     // F·µ¢ = Fisher information (importance)
          </ns0:text>
          <ns0:text x="0" y="680.0" font-size="11" fill="#1a237e">
            Weights important for T‚ÇÅ are protected when learning T‚ÇÇ
          </ns0:text>
        </ns0:g>
      </ns0:g>
      <ns0:g transform="translate(0, 90)">
        <ns0:text x="0" y="705.0" font-size="13" font-weight="bold" fill="#145a32">
          B. Replay-Based: Rehearse old tasks
        </ns0:text>
        <ns0:rect x="0" y="10" width="940" height="60" fill="#1a237e" stroke="#28a745" stroke-width="2" rx="3"/>
        <ns0:g transform="translate(15, 28)">
          <ns0:text x="0" y="730.0" font-size="12" fill="#1a237e">
            <ns0:tspan font-weight="bold" fill="#145a32">Experience Replay:</ns0:tspan>
            Store subset of old task data in memory buffer ‚Üí Mix with new task data
          </ns0:text>
          <ns0:text x="0" y="755.0" font-size="12" fill="#1a237e">
            <ns0:tspan font-weight="bold" fill="#145a32">Generative Replay:</ns0:tspan>
            Train generative model on T‚ÇÅ ‚Üí Generate &quot;pseudo-examples&quot; when learning T‚ÇÇ
          </ns0:text>
          <ns0:text x="0" y="780.0" font-size="11" fill="#1a237e">
            ‚úì Effective ‚Ä¢ ‚úó Requires memory or extra model
          </ns0:text>
        </ns0:g>
      </ns0:g>
      <ns0:g transform="translate(0, 180)">
        <ns0:text x="0" y="805.0" font-size="13" font-weight="bold" fill="#145a32">
          C. Architecture-Based: Allocate capacity per task
        </ns0:text>
        <ns0:rect x="0" y="10" width="940" height="45" fill="#1a237e" stroke="#28a745" stroke-width="2" rx="3"/>
        <ns0:g transform="translate(15, 28)">
          <ns0:text x="0" y="830.0" font-size="12" fill="#1a237e">
            <ns0:tspan font-weight="bold" fill="#145a32">Progressive Neural Networks:</ns0:tspan>
            Add new columns for each task, freeze old columns
          </ns0:text>
          <ns0:text x="0" y="855.0" font-size="12" fill="#1a237e">
            <ns0:tspan font-weight="bold" fill="#145a32">PackNet:</ns0:tspan>
            Prune network after each task, reuse pruned capacity for new tasks
          </ns0:text>
        </ns0:g>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:rect x="50" y="800" width="2250.0" height="80" fill="#1a237e" stroke="#6f42c1" stroke-width="3" rx="8"/>
  <ns0:text x="550" y="880.0" font-size="15" font-weight="bold" text-anchor="middle" fill="#6c3483">
    üìä Evaluation Metrics
  </ns0:text>
  <ns0:g transform="translate(70, 850)">
    <ns0:text x="0" y="905.0" font-size="13" fill="#1a237e">
      ‚Ä¢ 
      <ns0:tspan font-weight="bold" fill="#6a1b9a">Average Accuracy:</ns0:tspan>
      Mean performance across all tasks after learning all of them
    </ns0:text>
    <ns0:text x="0" y="930.0" font-size="13" fill="#1a237e">
      ‚Ä¢ 
      <ns0:tspan font-weight="bold" fill="#6a1b9a">Backward Transfer:</ns0:tspan>
      How much learning new tasks hurts old task performance (negative = forgetting)
    </ns0:text>
  </ns0:g>
</ns0:svg>
