<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=1ABC9C&height=120&section=header&text=Efficient%20Machine%20Learning&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-09-1ABC9C?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## ğŸ“Š Learning Path

```
ğŸš€ Start --â–¶ ğŸ“Š Basics --â–¶ âœ‚ï¸ Pruning --â–¶ ğŸ”¢ Quantize --â–¶ ğŸ” NAS --â–¶ ğŸ“± TinyML --â–¶ âš¡ Training --â–¶ ğŸ† Expert
```

## ğŸ¯ What You'll Learn

> ğŸš€ **From Cloud to Edge**: Deploy AI on phones, microcontrollers, and edge devices

<table>
<tr>
<td align="center">

### âœ‚ï¸ Pruning
50-90% sparse

</td>
<td align="center">

### ğŸ”¢ Quantization
GPTQ, AWQ, QLoRA

</td>
<td align="center">

### ğŸ“± TinyML
256KB inference!

</td>
<td align="center">

### âš¡ Flash Attention
5x faster

</td>
</tr>
</table>

---

## ğŸ“š Course Modules

### ğŸ“– Lectures 1-2: Introduction & Basics

<img src="https://img.shields.io/badge/Time-3_hours-blue?style=flat-square"/>

```
Why Efficiency --â–¶ FLOPs --â–¶ Memory --â–¶ Roofline --â–¶ Profiling
```

> ğŸ’¡ **"Memory is the bottleneck, not compute"**

<a href="./01_introduction/"><img src="https://img.shields.io/badge/ğŸ“–_Notes-4CAF50?style=for-the-badge" alt="Notes"/></a>
<a href="https://colab.research.google.com/github/Gaurav14cs17/ml-researcher-foundations/blob/main/09_efficient_ml/01_introduction/demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab"/></a>

---

### âœ‚ï¸ Lectures 3-4: Pruning & Sparsity

<img src="https://img.shields.io/badge/Time-4_hours-blue?style=flat-square"/>

```
Dense --â–¶ Magnitude --â–¶ Sparse --â–¶ Lottery Ticket --â–¶ Structured
```

**Key:** Lottery Ticket Hypothesis, 50-90% sparsity

<a href="./03_pruning_sparsity_1/"><img src="https://img.shields.io/badge/ğŸ“–_Notes-4CAF50?style=for-the-badge" alt="Notes"/></a>
<a href="https://colab.research.google.com/github/Gaurav14cs17/ml-researcher-foundations/blob/main/09_efficient_ml/03_pruning_sparsity_1/demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab"/></a>

---

### ğŸ”¢ Lectures 5-6: Quantization â­

<img src="https://img.shields.io/badge/Time-6_hours-blue?style=flat-square"/> <img src="https://img.shields.io/badge/ğŸ”¥_HOT-critical?style=flat-square"/>

```
FP32 --â–¶ INT8 --â–¶ INT4 --â–¶ GPTQ --â–¶ QLoRA
```

> ğŸ”¥ **QLoRA: Train 65B on single GPU**

<a href="./05_quantization_1/"><img src="https://img.shields.io/badge/ğŸ“–_Notes-4CAF50?style=for-the-badge" alt="Notes"/></a>
<a href="https://colab.research.google.com/github/Gaurav14cs17/ml-researcher-foundations/blob/main/09_efficient_ml/05_quantization_1/demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab"/></a>

---

### ğŸ” Lectures 7-8: Neural Architecture Search

<img src="https://img.shields.io/badge/Time-4_hours-blue?style=flat-square"/>

```
Manual --â–¶ AutoML --â–¶ DARTS --â–¶ Once-for-All --â–¶ Efficient
```

<a href="./07_neural_architecture_search_1/"><img src="https://img.shields.io/badge/ğŸ“–_Notes-4CAF50?style=for-the-badge" alt="Notes"/></a>
<a href="https://colab.research.google.com/github/Gaurav14cs17/ml-researcher-foundations/blob/main/09_efficient_ml/07_neural_architecture_search_1/demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab"/></a>

---

### ğŸ“± Lectures 9-10: Distillation & TinyML

<img src="https://img.shields.io/badge/Time-4_hours-blue?style=flat-square"/>

```
Teacher --â–¶ Distill --â–¶ Student --â–¶ MCUNet --â–¶ 256KB
```

> ğŸ“± **MCUNet: Run ML on 256KB microcontrollers**

<a href="./09_knowledge_distillation/"><img src="https://img.shields.io/badge/ğŸ“–_Notes-4CAF50?style=for-the-badge" alt="Notes"/></a>
<a href="https://colab.research.google.com/github/Gaurav14cs17/ml-researcher-foundations/blob/main/09_efficient_ml/09_knowledge_distillation/demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab"/></a>

---

### âš¡ Lectures 11-12: Efficient Transformers ğŸ”¥

<img src="https://img.shields.io/badge/Time-5_hours-blue?style=flat-square"/> <img src="https://img.shields.io/badge/ğŸ”¥_ESSENTIAL-critical?style=flat-square"/>

```
Standard --â–¶ FlashAttention --â–¶ Linear --â–¶ Sparse --â–¶ 10x Fast
```

> âš¡ **Flash Attention: 5x faster, O(n) memory** - In all modern LLMs

<a href="./11_efficient_transformers/"><img src="https://img.shields.io/badge/ğŸ“–_Notes-4CAF50?style=for-the-badge" alt="Notes"/></a>
<a href="https://colab.research.google.com/github/Gaurav14cs17/ml-researcher-foundations/blob/main/09_efficient_ml/11_efficient_transformers/demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab"/></a>

---

### ğŸŒ Lectures 13-14: Distributed Training

<img src="https://img.shields.io/badge/Time-5_hours-blue?style=flat-square"/>

```
Single GPU --â–¶ Data Parallel --â–¶ Model Parallel --â–¶ ZeRO --â–¶ Trillion
```

**Core:** ZeRO, FSDP, DeepSpeed, Megatron

<a href="./14_distributed_training/"><img src="https://img.shields.io/badge/ğŸ“–_Notes-4CAF50?style=for-the-badge" alt="Notes"/></a>
<a href="https://colab.research.google.com/github/Gaurav14cs17/ml-researcher-foundations/blob/main/09_efficient_ml/14_distributed_training/demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab"/></a>

---

### ğŸš€ Lectures 15-18: Efficient Models

<img src="https://img.shields.io/badge/Time-6_hours-blue?style=flat-square"/>

```
LLMs --â–¶ Diffusion --â–¶ Vision --â–¶ Production
```

**Covered:** LLaMA, Stable Diffusion, MobileNets, Edge Deployment

<a href="./16_efficient_llms/"><img src="https://img.shields.io/badge/ğŸ“–_LLMs-4CAF50?style=for-the-badge" alt="LLMs"/></a>
<a href="./17_efficient_diffusion_models/"><img src="https://img.shields.io/badge/ğŸ“–_Diffusion-4CAF50?style=for-the-badge" alt="Diffusion"/></a>
<a href="./15_efficient_vision_models/"><img src="https://img.shields.io/badge/ğŸ“–_Vision-4CAF50?style=for-the-badge" alt="Vision"/></a>

---

## ğŸ’¡ Key Takeaways

<table>
<tr>
<td>

### ğŸ“Š Roofline Model
```
Perf = min(Peak_Compute, 
           Peak_BW Ã— Intensity)
```

</td>
<td>

### ğŸ”¢ Quantization
```
FP32 â†’ INT8: 4x smaller
FP32 â†’ INT4: 8x smaller
2-4x speedup
```

</td>
<td>

### âš¡ Flash Attention
```
Standard: O(NÂ²) memory
Flash: O(N) memory
5x faster!
```

</td>
</tr>
</table>

---

## ğŸ”— Course Structure

| Week | Lectures | Topics | Lab |
|:----:|:--------:|--------|:---:|
| 1-2 | L1-L4 | Intro, Pruning | âœ‚ï¸ |
| 3-4 | L5-L8 | Quantization, NAS | ğŸ”¢ |
| 5-6 | L9-L10 | Distillation, TinyML | ğŸ“± |
| 7-8 | L11-L14 | Transformers, Training | âš¡ |
| 9-10 | L15-L18 | Production Models | ğŸš€ |

---

## ğŸ› ï¸ Tools You'll Use

<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch"/>
  <img src="https://img.shields.io/badge/bitsandbytes-Quantization-blue?style=for-the-badge" alt="bitsandbytes"/>
  <img src="https://img.shields.io/badge/PEFT-LoRA-green?style=for-the-badge" alt="PEFT"/>
  <img src="https://img.shields.io/badge/DeepSpeed-Training-orange?style=for-the-badge" alt="DeepSpeed"/>
</p>

---

## ğŸ“š Official Resources

| Resource | Link |
|:--------:|------|
| ğŸ“º **Course Website** | [hanlab.mit.edu](https://hanlab.mit.edu/courses/2023-fall-65940) |
| ğŸ“º **YouTube Playlist** | [Watch Lectures](https://www.youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB) |
| ğŸ“ **Lecture Slides** | [Download PDFs](https://hanlab.mit.edu/courses/2023-fall-65940) |

---

## ğŸ—ºï¸ Quick Navigation

| Previous | Current | Next |
|:--------:|:-------:|:----:|
| [ğŸ—œï¸ Compression](../08_model_compression/README.md) | **âš¡ Efficient ML** | ğŸ† **Production Ready!** |

---

<p align="center">
  <b>ğŸ“ Ready to deploy AI anywhere?</b>
  <br/><br/>
  <a href="./01_introduction/"><img src="https://img.shields.io/badge/Start_Learning_â†’-4CAF50?style=for-the-badge&logo=rocket&logoColor=white" alt="Start"/></a>
</p>

---

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=1ABC9C&height=80&section=footer" width="100%"/>
</p>
