<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 2475.0 2025.0">
  <ns0:text x="550" y="30" font-size="22" font-weight="bold" text-anchor="middle" fill="#1a237e">
    Model Interpretability: Understanding Black-Box Predictions
  </ns0:text>
  <ns0:g transform="translate(50, 80)">
    <ns0:text x="500" y="55.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#1565c0">
      1. Why Interpretability Matters
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="225.0" fill="#f8f9fa" stroke="#007bff" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="80.0" font-size="13" fill="#1a237e">
        • 
        <ns0:tspan font-weight="bold" fill="#1565c0">Trust:</ns0:tspan>
        Verify model makes decisions for right reasons (not spurious correlations)
      </ns0:text>
      <ns0:text x="0" y="105.0" font-size="13" fill="#1a237e">
        • 
        <ns0:tspan font-weight="bold" fill="#1565c0">Debugging:</ns0:tspan>
        Identify biases, errors, or data leakage
      </ns0:text>
      <ns0:text x="0" y="130.0" font-size="13" fill="#1a237e">
        • 
        <ns0:tspan font-weight="bold" fill="#1565c0">Compliance:</ns0:tspan>
        Legal requirements (GDPR &quot;right to explanation&quot;), medical/financial domains
      </ns0:text>
      <ns0:text x="0" y="155.0" font-size="13" fill="#1a237e">
        • 
        <ns0:tspan font-weight="bold" fill="#1565c0">Science:</ns0:tspan>
        Discover new insights from model's learned patterns
      </ns0:text>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 220)">
    <ns0:text x="500" y="180.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#2e7d32">
      2. Feature Importance (Global)
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="160" fill="#1a237e" stroke="#28a745" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="205.0" font-size="14" font-weight="bold" fill="#145a32">
        Which features matter most for predictions overall?
      </ns0:text>
      <ns0:g transform="translate(50, 30)">
        <ns0:g>
          <ns0:text x="-10" y="230.0" font-size="11" text-anchor="end" fill="#1a237e">Age</ns0:text>
          <ns0:rect x="0" y="5" width="300" height="18" fill="#2e7d32" opacity="0.8"/>
          <ns0:text x="310" y="255.0" font-size="10" fill="#145a32" font-weight="bold">0.42</ns0:text>
        </ns0:g>
        <ns0:g transform="translate(0, 28)">
          <ns0:text x="-10" y="280.0" font-size="11" text-anchor="end" fill="#1a237e">Income</ns0:text>
          <ns0:rect x="0" y="5" width="240" height="18" fill="#2e7d32" opacity="0.8"/>
          <ns0:text x="250" y="305.0" font-size="10" fill="#145a32" font-weight="bold">0.35</ns0:text>
        </ns0:g>
        <ns0:g transform="translate(0, 56)">
          <ns0:text x="-10" y="330.0" font-size="11" text-anchor="end" fill="#1a237e">Education</ns0:text>
          <ns0:rect x="0" y="5" width="120" height="18" fill="#2e7d32" opacity="0.8"/>
          <ns0:text x="130" y="355.0" font-size="10" fill="#145a32" font-weight="bold">0.18</ns0:text>
        </ns0:g>
        <ns0:g transform="translate(0, 84)">
          <ns0:text x="-10" y="380.0" font-size="11" text-anchor="end" fill="#1a237e">Location</ns0:text>
          <ns0:rect x="0" y="5" width="40" height="18" fill="#2e7d32" opacity="0.8"/>
          <ns0:text x="50" y="405.0" font-size="10" fill="#145a32" font-weight="bold">0.05</ns0:text>
        </ns0:g>
        <ns0:text x="400" y="430.0" font-size="12" fill="#1a237e">
          Methods:
        </ns0:text>
        <ns0:text x="400" y="455.0" font-size="11" fill="#1a237e">
          • Tree-based: Gini importance
        </ns0:text>
        <ns0:text x="400" y="480.0" font-size="11" fill="#1a237e">
          • Permutation importance
        </ns0:text>
        <ns0:text x="400" y="505.0" font-size="11" fill="#1a237e">
          • Drop-column importance
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 420)">
    <ns0:text x="500" y="530.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#6a1b9a">
      3. LIME (Local Interpretable Model-agnostic Explanations)
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="200" fill="#1a237e" stroke="#6f42c1" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="555.0" font-size="14" font-weight="bold" fill="#6c3483">
        Explain individual predictions by fitting a simple model locally
      </ns0:text>
      <ns0:g transform="translate(0, 30)">
        <ns0:g>
          <ns0:rect x="0" y="0" width="180" height="60" fill="#1a237e" stroke="#6f42c1" stroke-width="1" rx="3"/>
          <ns0:g transform="translate(10, 15)">
            <ns0:text x="0" y="580.0" font-size="11" font-weight="bold" fill="#6a1b9a">
              1. Perturb input
            </ns0:text>
            <ns0:text x="0" y="605.0" font-size="10" fill="#1a237e">
              Create variations
            </ns0:text>
            <ns0:text x="0" y="630.0" font-size="10" fill="#1a237e">
              near test point
            </ns0:text>
          </ns0:g>
        </ns0:g>
        <ns0:g transform="translate(200, 0)">
          <ns0:rect x="0" y="0" width="180" height="60" fill="#1a237e" stroke="#6f42c1" stroke-width="1" rx="3"/>
          <ns0:g transform="translate(10, 15)">
            <ns0:text x="0" y="655.0" font-size="11" font-weight="bold" fill="#6a1b9a">
              2. Get predictions
            </ns0:text>
            <ns0:text x="0" y="680.0" font-size="10" fill="#1a237e">
              Run black-box
            </ns0:text>
            <ns0:text x="0" y="705.0" font-size="10" fill="#1a237e">
              on all variants
            </ns0:text>
          </ns0:g>
        </ns0:g>
        <ns0:g transform="translate(400, 0)">
          <ns0:rect x="0" y="0" width="180" height="60" fill="#1a237e" stroke="#6f42c1" stroke-width="1" rx="3"/>
          <ns0:g transform="translate(10, 15)">
            <ns0:text x="0" y="730.0" font-size="11" font-weight="bold" fill="#6a1b9a">
              3. Fit linear model
            </ns0:text>
            <ns0:text x="0" y="755.0" font-size="10" fill="#1a237e">
              Weight by distance
            </ns0:text>
            <ns0:text x="0" y="780.0" font-size="10" fill="#1a237e">
              to test point
            </ns0:text>
          </ns0:g>
        </ns0:g>
        <ns0:g transform="translate(600, 0)">
          <ns0:rect x="0" y="0" width="180" height="60" fill="#1a237e" stroke="#6f42c1" stroke-width="1" rx="3"/>
          <ns0:g transform="translate(10, 15)">
            <ns0:text x="0" y="805.0" font-size="11" font-weight="bold" fill="#6a1b9a">
              4. Interpret
            </ns0:text>
            <ns0:text x="0" y="830.0" font-size="10" fill="#1a237e">
              Linear coefficients
            </ns0:text>
            <ns0:text x="0" y="855.0" font-size="10" fill="#1a237e">
              → feature importance
            </ns0:text>
          </ns0:g>
        </ns0:g>
      </ns0:g>
      <ns0:g transform="translate(0, 105)">
        <ns0:text x="0" y="880.0" font-size="12" fill="#1a237e">
          <ns0:tspan font-weight="bold" fill="#6a1b9a">Example:</ns0:tspan>
          &quot;This loan was rejected because low income (-0.3) and short credit history (-0.2)&quot;
        </ns0:text>
        <ns0:text x="0" y="905.0" font-size="12" fill="#2e7d32">
          ✓ Model-agnostic (works for any model)
        </ns0:text>
        <ns0:text x="350" y="930.0" font-size="12" fill="#2e7d32">
          ✓ Human-interpretable (sparse linear)
        </ns0:text>
        <ns0:text x="0" y="955.0" font-size="12" fill="#c62828">
          ✗ Can be unstable • ✗ Only local (one prediction at a time)
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 660)">
    <ns0:text x="500" y="980.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#e67e22">
      4. SHAP (SHapley Additive exPlanations)
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="200" fill="#1a237e" stroke="#fd7e14" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="1005.0" font-size="14" font-weight="bold" fill="#d35400">
        Based on Shapley values from game theory → Fair contribution of each feature
      </ns0:text>
      <ns0:g transform="translate(0, 30)">
        <ns0:text x="0" y="1030.0" font-size="13" font-family="Arial, sans-serif" fill="#d84315">
          φᵢ(x) = Σ_{S⊆F\{i}} [|S|!(|F|-|S|-1)! / |F|!] [f(S∪{i}) - f(S)]
        </ns0:text>
        <ns0:text x="0" y="1055.0" font-size="11" fill="#1a237e">
          <ns0:tspan x="0" dy="0">φᵢ = SHAP value for feature i • Average marginal</ns0:tspan>
          <ns0:tspan x="0" dy="1.2em">contribution across all coalitions</ns0:tspan>
        </ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 70)">
        <ns0:text x="0" y="1080.0" font-size="12" font-weight="bold" fill="#d35400">
          Example (House Price Prediction):
        </ns0:text>
        <ns0:g transform="translate(0, 20)">
          <ns0:text x="0" y="1105.0" font-size="11" fill="#1a237e">
            Base value: $200k
          </ns0:text>
          <ns0:text x="0" y="1130.0" font-size="11" fill="#2e7d32">
            + Location = +$50k
          </ns0:text>
          <ns0:text x="0" y="1155.0" font-size="11" fill="#2e7d32">
            + Size = +$30k
          </ns0:text>
          <ns0:text x="0" y="1180.0" font-size="11" fill="#c62828">
            - Age = -$10k
          </ns0:text>
          <ns0:text x="0" y="1205.0" font-size="11" fill="#1a237e" font-weight="bold">
            = Prediction: $270k
          </ns0:text>
        </ns0:g>
        <ns0:g transform="translate(300, 0)">
          <ns0:text x="0" y="1230.0" font-size="12" font-weight="bold" fill="#d35400">
            Properties:
          </ns0:text>
          <ns0:text x="0" y="1255.0" font-size="11" fill="#2e7d32">
            ✓ Theoretically grounded (game theory)
          </ns0:text>
          <ns0:text x="0" y="1280.0" font-size="11" fill="#2e7d32">
            ✓ Local + global explanations
          </ns0:text>
          <ns0:text x="0" y="1305.0" font-size="11" fill="#2e7d32">
            ✓ Consistent and additive
          </ns0:text>
          <ns0:text x="0" y="1330.0" font-size="11" fill="#c62828">
            ✗ Computationally expensive
          </ns0:text>
        </ns0:g>
        <ns0:g transform="translate(600, 0)">
          <ns0:text x="0" y="1355.0" font-size="12" font-weight="bold" fill="#d35400">
            Variants:
          </ns0:text>
          <ns0:text x="0" y="1380.0" font-size="11" fill="#1a237e">
            • TreeSHAP (fast for trees)
          </ns0:text>
          <ns0:text x="0" y="1405.0" font-size="11" fill="#1a237e">
            • DeepSHAP (for neural nets)
          </ns0:text>
          <ns0:text x="0" y="1430.0" font-size="11" fill="#1a237e">
            • KernelSHAP (model-agnostic)
          </ns0:text>
        </ns0:g>
      </ns0:g>
    </ns0:g>
  </ns0:g>
</ns0:svg>
