<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 2475.0 1912.5">
  <ns0:text x="550" y="30" font-size="22" font-weight="bold" text-anchor="middle" fill="#1a237e">
    Entropy &amp; Information Theory: Complete Framework
  </ns0:text>
  <ns0:g transform="translate(50, 80)">
    <ns0:text x="500" y="55.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#1565c0">
      1. Shannon Entropy
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="405.0" fill="#f8f9fa" stroke="#007bff" stroke-width="3" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:text x="0" y="80.0" font-size="14" font-weight="bold" fill="#1565c0">
        Measures uncertainty/information content of a distribution
      </ns0:text>
      <ns0:rect x="0" y="20" width="940" height="50" fill="#1a237e" stroke="#007bff" stroke-width="1" rx="3"/>
      <ns0:text x="470" y="105.0" font-size="18" font-family="Arial, sans-serif" text-anchor="middle" fill="#1a5276">
        H(X) = -Σᵢ p(xᵢ) log₂ p(xᵢ)  (bits)
      </ns0:text>
      <ns0:g transform="translate(0, 85)">
        <ns0:text x="0" y="130.0" font-size="13" fill="#1a237e">
          <ns0:tspan font-weight="bold" fill="#1565c0">Interpretation:</ns0:tspan>
          Average number of bits needed to encode a random variable
        </ns0:text>
        <ns0:text x="0" y="155.0" font-size="13" fill="#1a237e">
          • 
          <ns0:tspan font-weight="bold" fill="#2e7d32">High entropy:</ns0:tspan>
          High uncertainty, need many bits (uniform distribution)
        </ns0:text>
        <ns0:text x="0" y="180.0" font-size="13" fill="#1a237e">
          • 
          <ns0:tspan font-weight="bold" fill="#c62828">Low entropy:</ns0:tspan>
          Low uncertainty, need few bits (peaked distribution)
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 300)">
    <ns0:text x="500" y="205.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#1a237e">
      2. Examples: Entropy of Different Distributions
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="240" fill="#1a237e" stroke="#e0e0e0" stroke-width="2" rx="8"/>
    <ns0:g transform="translate(60, 60)">
      <ns0:text x="110" y="230.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#c62828">
        Deterministic (H = 0)
      </ns0:text>
      <ns0:rect x="0" y="0" width="220" height="150" fill="#1a237e" stroke="#e0e0e0" stroke-width="1" rx="8"/>
      <ns0:rect x="30" y="120" width="40" height="20" fill="#c62828" opacity="0.7"/>
      <ns0:rect x="90" y="20" width="40" height="120" fill="#c62828"/>
      <ns0:rect x="150" y="120" width="40" height="20" fill="#c62828" opacity="0.7"/>
      <ns0:text x="50" y="255.0" font-size="10" text-anchor="middle" fill="#1a237e">p=0</ns0:text>
      <ns0:text x="110" y="280.0" font-size="10" text-anchor="middle" fill="#1a237e" font-weight="bold">p=1</ns0:text>
      <ns0:text x="170" y="305.0" font-size="10" text-anchor="middle" fill="#1a237e">p=0</ns0:text>
      <ns0:text x="110" y="330.0" font-size="11" text-anchor="middle" fill="#c62828" font-weight="bold">
        No uncertainty!
      </ns0:text>
    </ns0:g>
    <ns0:g transform="translate(320, 60)">
      <ns0:text x="110" y="355.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#e65100">
        Fair Coin (H = 1 bit)
      </ns0:text>
      <ns0:rect x="0" y="0" width="220" height="150" fill="#1a237e" stroke="#e0e0e0" stroke-width="1" rx="8"/>
      <ns0:rect x="50" y="50" width="50" height="90" fill="#e65100"/>
      <ns0:rect x="120" y="50" width="50" height="90" fill="#e65100"/>
      <ns0:text x="75" y="380.0" font-size="10" text-anchor="middle" fill="#1a237e">H</ns0:text>
      <ns0:text x="75" y="405.0" font-size="10" text-anchor="middle" fill="#1a237e">p=0.5</ns0:text>
      <ns0:text x="145" y="430.0" font-size="10" text-anchor="middle" fill="#1a237e">T</ns0:text>
      <ns0:text x="145" y="455.0" font-size="10" text-anchor="middle" fill="#1a237e">p=0.5</ns0:text>
      <ns0:text x="110" y="480.0" font-size="11" text-anchor="middle" fill="#e65100" font-weight="bold">
        Maximum entropy!
      </ns0:text>
    </ns0:g>
    <ns0:g transform="translate(580, 60)">
      <ns0:text x="110" y="505.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#1565c0">
        Biased Coin (H ≈ 0.72)
      </ns0:text>
      <ns0:rect x="0" y="0" width="220" height="150" fill="#1a237e" stroke="#e0e0e0" stroke-width="1" rx="8"/>
      <ns0:rect x="50" y="30" width="50" height="110" fill="#1565c0"/>
      <ns0:rect x="120" y="90" width="50" height="50" fill="#1565c0" opacity="0.7"/>
      <ns0:text x="75" y="530.0" font-size="10" text-anchor="middle" fill="#1a237e">H</ns0:text>
      <ns0:text x="75" y="555.0" font-size="10" text-anchor="middle" fill="#1a237e">p=0.8</ns0:text>
      <ns0:text x="145" y="580.0" font-size="10" text-anchor="middle" fill="#1a237e">T</ns0:text>
      <ns0:text x="145" y="605.0" font-size="10" text-anchor="middle" fill="#1a237e">p=0.2</ns0:text>
      <ns0:text x="110" y="630.0" font-size="11" text-anchor="middle" fill="#1565c0" font-weight="bold">
        Less uncertain
      </ns0:text>
    </ns0:g>
    <ns0:g transform="translate(840, 60)">
      <ns0:text x="75" y="655.0" font-size="13" font-weight="bold" text-anchor="middle" fill="#2e7d32">
        8-sided Die (H = 3 bits)
      </ns0:text>
      <ns0:rect x="0" y="0" width="150" height="150" fill="#1a237e" stroke="#e0e0e0" stroke-width="1" rx="8"/>
      <ns0:rect x="10" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:rect x="27" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:rect x="44" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:rect x="61" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:rect x="78" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:rect x="95" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:rect x="112" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:rect x="129" y="80" width="15" height="60" fill="#2e7d32"/>
      <ns0:text x="75" y="680.0" font-size="10" text-anchor="middle" fill="#1a237e">p=1/8 each</ns0:text>
      <ns0:text x="75" y="705.0" font-size="11" text-anchor="middle" fill="#2e7d32" font-weight="bold">
        log₂(8) = 3 bits
      </ns0:text>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 580)">
    <ns0:text x="500" y="730.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#2e7d32">
      3. Key Properties
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="140" fill="#1a237e" stroke="#28a745" stroke-width="2" rx="8"/>
    <ns0:g transform="translate(30, 50)">
      <ns0:g>
        <ns0:circle cx="8" cy="-3" r="8" fill="#2e7d32"/>
        <ns0:text x="8" y="755.0" font-size="11" font-weight="bold" text-anchor="middle" fill="#1a237e">1</ns0:text>
        <ns0:text x="25" y="780.0" font-size="13" fill="#1a237e">
          <ns0:tspan font-weight="bold" fill="#145a32">Non-negativity:</ns0:tspan>
          <ns0:tspan font-family="Arial, sans-serif">H(X) ≥ 0</ns0:tspan>
          (equality when X is deterministic)
        </ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 28)">
        <ns0:circle cx="8" cy="-3" r="8" fill="#2e7d32"/>
        <ns0:text x="8" y="805.0" font-size="11" font-weight="bold" text-anchor="middle" fill="#1a237e">2</ns0:text>
        <ns0:text x="25" y="830.0" font-size="13" fill="#1a237e">
          <ns0:tspan font-weight="bold" fill="#145a32">Maximum:</ns0:tspan>
          <ns0:tspan font-family="Arial, sans-serif">H(X) ≤ log₂|X|</ns0:tspan>
          (equality when uniform: all outcomes equally likely)
        </ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 56)">
        <ns0:circle cx="8" cy="-3" r="8" fill="#2e7d32"/>
        <ns0:text x="8" y="855.0" font-size="11" font-weight="bold" text-anchor="middle" fill="#1a237e">3</ns0:text>
        <ns0:text x="25" y="880.0" font-size="13" fill="#1a237e">
          <ns0:tspan font-weight="bold" fill="#145a32">Chain Rule:</ns0:tspan>
          <ns0:tspan font-family="Arial, sans-serif">H(X,Y) = H(X) + H(Y|X)</ns0:tspan>
          (joint entropy = marginal + conditional)
        </ns0:text>
      </ns0:g>
      <ns0:g transform="translate(0, 84)">
        <ns0:circle cx="8" cy="-3" r="8" fill="#2e7d32"/>
        <ns0:text x="8" y="905.0" font-size="11" font-weight="bold" text-anchor="middle" fill="#1a237e">4</ns0:text>
        <ns0:text x="25" y="930.0" font-size="13" fill="#1a237e">
          <ns0:tspan font-weight="bold" fill="#145a32">Conditioning reduces entropy:</ns0:tspan>
          <ns0:tspan font-family="Arial, sans-serif">H(X|Y) ≤ H(X)</ns0:tspan>
          (knowing Y can only reduce uncertainty about X)
        </ns0:text>
      </ns0:g>
    </ns0:g>
  </ns0:g>
  <ns0:g transform="translate(50, 760)">
    <ns0:text x="500" y="955.0" font-size="16" font-weight="bold" text-anchor="middle" fill="#6a1b9a">
      4. Related Concepts
    </ns0:text>
    <ns0:rect x="0" y="20" width="2250.0" height="60" fill="#1a237e" stroke="#6f42c1" stroke-width="2" rx="8"/>
    <ns0:g transform="translate(30, 45)">
      <ns0:text x="0" y="980.0" font-size="13" fill="#1a237e">
        <ns0:tspan font-weight="bold" fill="#6a1b9a">• Mutual Information I(X;Y):</ns0:tspan>
        <ns0:tspan font-family="Arial, sans-serif">H(X) + H(Y) - H(X,Y)</ns0:tspan>
        <ns0:tspan fill="#1a237e"> — How much knowing Y tells us about X</ns0:tspan>
      </ns0:text>
      <ns0:text x="0" y="1005.0" font-size="13" fill="#1a237e">
        <ns0:tspan font-weight="bold" fill="#6a1b9a">• Cross-Entropy H(p,q):</ns0:tspan>
        <ns0:tspan font-family="Arial, sans-serif">-Σᵢ p(xᵢ) log q(xᵢ)</ns0:tspan>
        <ns0:tspan fill="#1a237e"> — Expected bits using &quot;wrong&quot; distribution q</ns0:tspan>
        <ns0:tspan dx="20" font-weight="bold" fill="#c62828">→ Loss function for classification!</ns0:tspan>
      </ns0:text>
    </ns0:g>
  </ns0:g>
</ns0:svg>
