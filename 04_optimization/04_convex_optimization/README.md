<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=120&section=header&text=Convex%20Optimization&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-04-FF6B6B?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## ğŸ“‚ Subtopics

| Folder | Topic | Why Important |
|--------|-------|---------------|
| [01_elbo/](./01_elbo/) | ELBO & Variational Inference | VAE, Diffusion! |

---

## ğŸ¯ What is Convex Optimization?

A convex optimization problem has:
1. **Convex objective** function (bowl-shaped)
2. **Convex constraint** set (no holes, connected)

```
+---------------------------------------------------------+
|                                                         |
|   CONVEX OPTIMIZATION PROBLEM:                          |
|                                                         |
|   minimize   f(x)      where f is convex               |
|   subject to gáµ¢(x) â‰¤ 0  where gáµ¢ are convex            |
|              Ax = b                                     |
|                                                         |
|   KEY PROPERTY: Any local minimum = global minimum!    |
|                                                         |
+---------------------------------------------------------+
```

---

## ğŸ¯ Why Convexity Matters

```
NON-CONVEX (typical DL):           CONVEX:

        â€¢  local min                    
       â•± â•²                              
      â•±   â•²     â€¢  local min             â•²     â•±
     â•±     â•²   â•± â•²                        â•²   â•±
    â•±       â•²-â•±   â•²                        â•² â•±
                   â•²____â€¢ global            â€¢
                                        global = local!

â€¢ Many local minima              â€¢ Only one minimum
â€¢ SGD might get stuck            â€¢ Any method finds it
â€¢ Need good initialization       â€¢ Initialization irrelevant
```

---

## ğŸ“ Definition of Convex Function

### Formal Definition

A function f is **CONVEX** if for all x, y and Î¸ âˆˆ [0,1]:

\[f(\theta x + (1-\theta)y) \leq \theta f(x) + (1-\theta)f(y)\]

Visually: The chord is ABOVE the function

```
            â€¢ f(x)
           â•±|
          â•± |   chord
         â•±  |
        â•±   |
       â•±    â€¢ f(y)
      â•±------------
     â•±   function
    â€¢  below chord âœ“
```

### Second-Order Conditions

```
For twice-differentiable f:

f is convex âŸº âˆ‡Â²f(x) â‰½ 0 (Hessian is positive semidefinite)
f is strictly convex âŸº âˆ‡Â²f(x) â‰» 0 (Hessian is positive definite)

Example: f(x) = Â½xáµ€Qx + báµ€x
âˆ‡f(x) = Qx + b
âˆ‡Â²f(x) = Q
Convex âŸº Q â‰½ 0
```

### First-Order Conditions

```
For differentiable convex f:

f(y) â‰¥ f(x) + âˆ‡f(x)áµ€(y - x)

The tangent line/plane is BELOW the function!
Used in gradient descent convergence proofs.
```

---

## ğŸ“ Strong Convexity

```
f is Î¼-strongly convex if:

f(y) â‰¥ f(x) + âˆ‡f(x)áµ€(y - x) + (Î¼/2)â€–y - xâ€–Â²

Equivalently: âˆ‡Â²f(x) â‰½ Î¼I

Benefits:
â€¢ Unique global minimum
â€¢ Faster convergence: O((1-Î¼/L)^k) vs O(1/k)
â€¢ More stable optimization
```

---

## ğŸ“ Lipschitz Smoothness

```
f is L-smooth if gradient is Lipschitz:

â€–âˆ‡f(x) - âˆ‡f(y)â€– â‰¤ Lâ€–x - yâ€–

Equivalently: âˆ‡Â²f(x) â‰¼ LI

Used for: Learning rate bounds (Î± â‰¤ 1/L)
```

---

## ğŸ“ Convergence Rates

```
Gradient Descent: Î¸â‚œâ‚Šâ‚ = Î¸â‚œ - Î±âˆ‡f(Î¸â‚œ)

For L-smooth convex f with step Î± â‰¤ 1/L:
f(Î¸â‚œ) - f(Î¸*) â‰¤ O(1/t)

For L-smooth Î¼-strongly convex:
f(Î¸â‚œ) - f(Î¸*) â‰¤ O((1 - Î¼/L)^t)

Condition number Îº = L/Î¼ determines speed
```

---

## ğŸŒ Real-World Convex Problems

| Problem | Convex? | Why? |
|---------|---------|------|
| **Linear Regression** | âœ… Yes | Quadratic loss |
| **Logistic Regression** | âœ… Yes | Log-loss is convex |
| **SVM** | âœ… Yes | Hinge loss + L2 |
| **LASSO** | âœ… Yes | L1 regularized |
| **Portfolio Optimization** | âœ… Yes | Mean-variance |
| **Deep Learning** | âŒ No | Non-linear activations |
| **Matrix Factorization** | âŒ No | Product of unknowns |

---

## ğŸ“Š Convex Examples

| Function | Formula | Convex? |
|----------|---------|---------|
| Linear | f(x) = aáµ€x + b | âœ… Yes (and concave!) |
| Quadratic | f(x) = xáµ€Qx (Qâ‰»0) | âœ… Yes |
| Norm | f(x) = â€–xâ€– | âœ… Yes |
| Log-sum-exp | f(x) = log(Î£eË£â±) | âœ… Yes |
| Negative entropy | f(x) = Î£xáµ¢log(xáµ¢) | âœ… Yes |
| Exponential | f(x) = eË£ | âœ… Yes |
| xÂ³ | f(x) = xÂ³ | âŒ No |

---

## ğŸ’» Code: Check Convexity

```python
import numpy as np
from scipy.linalg import eigh

def is_convex_quadratic(Q):
    """Check if f(x) = x'Qx is convex by checking eigenvalues"""
    eigenvalues = eigh(Q, eigvals_only=True)
    return all(eigenvalues >= 0)

# Example: f(x,y) = xÂ² + yÂ² 
Q = np.array([[1, 0], [0, 1]])
print(f"Is f(x,y)=xÂ²+yÂ² convex? {is_convex_quadratic(Q)}")  # True

# Example: f(x,y) = xÂ² - yÂ²
Q = np.array([[1, 0], [0, -1]])
print(f"Is f(x,y)=xÂ²-yÂ² convex? {is_convex_quadratic(Q)}")  # False
```

---

# Part 2: ELBO (Evidence Lower Bound)

## ğŸ¯ What is ELBO?

```
Problem: We want to maximize log p(x) (log-likelihood)
         But it's intractable!

Solution: Maximize a lower bound instead = ELBO

+-----------------------------------------------------+
|                                                     |
|   log p(x) = ELBO + KL(q || p)                     |
|                                                     |
|   Since KL â‰¥ 0, we have:                           |
|                                                     |
|   log p(x) â‰¥ ELBO                                  |
|                                                     |
|   Maximizing ELBO â‰ˆ Maximizing log p(x)            |
|                                                     |
+-----------------------------------------------------+
```

---

## ğŸ“ ELBO Formula

```
ELBO = E_q(z|x)[log p(x|z)] - KL(q(z|x) || p(z))
       ---------------------   ------------------
       Reconstruction term      Regularization term
       
       "How well can we         "Stay close to 
        reconstruct x?"          the prior p(z)"
```

---

## ğŸ“ ELBO Decomposition (Derivation)

```
Start with log-likelihood:
  log p(x) = log âˆ« p(x,z) dz

Step 1: Introduce variational distribution q(z|x)
  log p(x) = log âˆ« q(z|x) [p(x,z)/q(z|x)] dz

Step 2: Apply Jensen's inequality (log is concave)
  log p(x) â‰¥ âˆ« q(z|x) log[p(x,z)/q(z|x)] dz  = ELBO

Step 3: Expand the bound
  ELBO = E_q[log p(x,z)] - E_q[log q(z|x)]
       = E_q[log p(x|z) + log p(z)] - E_q[log q(z|x)]
       = E_q[log p(x|z)] - KL(q(z|x) || p(z))

Step 4: Exact relationship
  log p(x) = ELBO + KL(q(z|x) || p(z|x))

Since KL â‰¥ 0, ELBO is always a lower bound.
Equality when q(z|x) = p(z|x) (true posterior).
```

---

## ğŸ“Š Three Ways to Write ELBO

```
1. ELBO = E_q[log p(x,z)] - E_q[log q(z)]

2. ELBO = E_q[log p(x|z)] - KL(q(z|x) || p(z))

3. ELBO = log p(x) - KL(q(z|x) || p(z|x))
```

---

## ğŸŒ Where ELBO is Used

| Model | How ELBO is Used | Paper |
|-------|------------------|-------|
| **VAE** | Main training objective | [Kingma 2013](https://arxiv.org/abs/1312.6114) |
| **Diffusion Models** | Variational bound on likelihood | [DDPM 2020](https://arxiv.org/abs/2006.11239) |
| **Bayesian NN** | Approximate posterior | [Weight Uncertainty](https://arxiv.org/abs/1505.05424) |
| **LLM Fine-tuning** | RLHF uses variational methods | [InstructGPT](https://arxiv.org/abs/2203.02155) |
| **Normalizing Flows** | Tighter ELBO with flows | [Rezende 2015](https://arxiv.org/abs/1505.05770) |

---

## ğŸ¨ ELBO in Diffusion Models

```
Forward Process (Add Noise):
x_0 --> x_1 --> x_2 --> ... --> x_T
 |       |       |              |
 v       v       v              v
Clean   Noisy   Noisier    Pure Noise

Reverse Process (Denoise):
x_T --> x_{T-1} --> ... --> x_1 --> x_0
 |         |               |       |
 v         v               v       v
Noise   Less Noisy      Cleaner  Clean!
```

### ELBO for Diffusion

```
+---------------------------------------------------------+
|                                                         |
|  log p(x_0) â‰¥ ELBO = E_q[ log p(x_T)                   |
|                          + Î£ log p(x_{t-1}|x_t)        |
|                          - Î£ log q(x_t|x_{t-1}) ]      |
|                                                         |
+---------------------------------------------------------+

Simplified Training Objective (DDPM):

L_simple = E_{t,x_0,Îµ}[ ||Îµ - Îµ_Î¸(x_t, t)||Â² ]

â€¢ t = random timestep
â€¢ Îµ = noise added at step t  
â€¢ Îµ_Î¸ = neural network predicting noise
```

### Connection to ELBO

```
Full ELBO decomposition:

L = L_0 + L_1 + ... + L_{T-1} + L_T

where each L_t is a KL divergence:

L_t = KL( q(x_{t-1}|x_t,x_0) || p_Î¸(x_{t-1}|x_t) )

Key insight:
â€¢ q(x_{t-1}|x_t,x_0) is Gaussian (tractable!)
â€¢ p_Î¸(x_{t-1}|x_t) is also Gaussian
â€¢ KL between Gaussians has closed form
â€¢ Reduces to ||Îµ - Îµ_Î¸||Â² loss!
```

---

## ğŸ’» Training Code (Simplified)

```python

# Diffusion Model Training with ELBO-based Loss
import torch
import torch.nn as nn

def train_step(model, x_0, noise_schedule):

    # Sample random timestep
    t = torch.randint(0, T, (batch_size,))
    
    # Sample noise
    epsilon = torch.randn_like(x_0)
    
    # Create noisy image: x_t = âˆšá¾±_t * x_0 + âˆš(1-á¾±_t) * Îµ
    alpha_bar = noise_schedule.alpha_bar[t]
    x_t = torch.sqrt(alpha_bar) * x_0 + torch.sqrt(1 - alpha_bar) * epsilon
    
    # Predict noise
    epsilon_pred = model(x_t, t)
    
    # ELBO-derived loss: ||Îµ - Îµ_Î¸(x_t, t)||Â²
    loss = nn.MSELoss()(epsilon_pred, epsilon)
    
    return loss
```

---

## ğŸ“š Resources

| Type | Title | Link |
|------|-------|------|
| ğŸ“– | Boyd & Vandenberghe | [Free PDF](https://web.stanford.edu/~boyd/cvxbook/) |
| ğŸ¥ | Stanford CVX101 | [YouTube](https://www.youtube.com/playlist?list=PL3940DD956CDF0622) |
| ğŸ“– | CMU 10-725 | [Course](https://www.stat.cmu.edu/~ryantibs/convexopt/) |
| ğŸ’» | CVXPY | [Docs](https://www.cvxpy.org/) |
| ğŸ“„ | VAE Original | [arXiv:1312.6114](https://arxiv.org/abs/1312.6114) |
| ğŸ“„ | DDPM (Diffusion) | [arXiv:2006.11239](https://arxiv.org/abs/2006.11239) |
| ğŸ‡¨ğŸ‡³ | å‡¸ä¼˜åŒ–å…¥é—¨ | [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/25383715) |
| ğŸ‡¨ğŸ‡³ | ELBOæ¨å¯¼è¯¦è§£ | [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/22464760) |

---

## ğŸ”— Where This Topic Is Used

| Topic | How Convexity Is Used |
|-------|----------------------|
| **SVM** | Dual is convex QP |
| **Logistic Regression** | Convex log-loss |
| **LASSO** | Convex L1 regularization |
| **Convergence Proofs** | Strong convexity bounds |
| **Neural Network Theory** | Local convexity analysis |
| **ELBO/VAE** | Variational lower bound |

---

â¬…ï¸ [Back: Advanced Methods](../03_advanced_methods/) | â¡ï¸ [Next: Constrained Optimization](../05_constrained_optimization/)

---

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=80&section=footer" width="100%"/>
</p>
