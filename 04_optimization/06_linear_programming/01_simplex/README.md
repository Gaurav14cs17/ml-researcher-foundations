<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=120&section=header&text=Simplex%20Algorithm&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-04-FF6B6B?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## üéØ Core Concept

The **simplex algorithm** solves linear programming problems by walking along the edges of the feasible polytope from vertex to vertex, always improving the objective, until reaching the optimum.

---

## üìê Linear Programming Problem

```
minimize    c·µÄx
subject to  Ax = b
            x ‚â• 0
            
Where:
  x ‚àà ‚Ñù‚Åø: decision variables
  A ‚àà ‚Ñù·µêÀ£‚Åø: constraint matrix
  b ‚àà ‚Ñù·µê: right-hand side
  c ‚àà ‚Ñù‚Åø: objective coefficients

```

**Standard form:** All constraints are equalities, all variables non-negative

---

## üîë Key Insight

### Fundamental Theorem of LP

```
If an optimal solution exists, then:
‚Ä¢ At least one optimal solution is a vertex (basic feasible solution)
‚Ä¢ The optimum occurs at a vertex of the feasible polytope

Therefore: Only check vertices, not interior points!

```

### Why Simplex Works

```
Feasible region: Polytope (convex polygon in n dimensions)
Vertices: Finite number
Edges: Connect adjacent vertices

Simplex:
1. Start at a vertex
2. Move to adjacent vertex with better objective
3. Repeat until no improvement possible

```

---

## üìê Algorithm

### Basic Steps

```
1. Find initial basic feasible solution (vertex)
2. While exists improving direction:
   a. Choose entering variable (pivot column)
   b. Choose leaving variable (pivot row)
   c. Perform pivot operation
   d. Update tableau
3. Return optimal solution

```

### Tableau Form

```
+------------------------------------+

|  z  |  -c·µÄ  | 0 |  ‚Üí  objective    |
+------------------------------------+

|  0  |   A   | b |  ‚Üí  constraints  |
+------------------------------------+
    ‚Üë      ‚Üë     ‚Üë
    z    vars  RHS

```

---

## üíª Example

**Problem:**

```
maximize   3x‚ÇÅ + 2x‚ÇÇ
subject to x‚ÇÅ + x‚ÇÇ ‚â§ 4
          2x‚ÇÅ + x‚ÇÇ ‚â§ 5
          x‚ÇÅ, x‚ÇÇ ‚â• 0

```

**Convert to standard form:**

```
minimize   -3x‚ÇÅ - 2x‚ÇÇ
subject to x‚ÇÅ + x‚ÇÇ + s‚ÇÅ = 4
          2x‚ÇÅ + x‚ÇÇ + s‚ÇÇ = 5
          x‚ÇÅ, x‚ÇÇ, s‚ÇÅ, s‚ÇÇ ‚â• 0

```

**Initial tableau:**

```
+---------------------------------+

| z | 3  2  0  0 | 0 |
+---------------------------------+

|s‚ÇÅ | 1  1  1  0 | 4 |
|s‚ÇÇ | 2  1  0  1 | 5 |
+---------------------------------+

```

**After pivots:**

```
Optimal: x‚ÇÅ = 1, x‚ÇÇ = 3
Objective: 3(1) + 2(3) = 9

```

---

## üíª Implementation

```python
import numpy as np
from scipy.optimize import linprog

# Problem: max 3x‚ÇÅ + 2x‚ÇÇ
#          s.t. x‚ÇÅ + x‚ÇÇ ‚â§ 4
#               2x‚ÇÅ + x‚ÇÇ ‚â§ 5

c = [-3, -2]  # Minimize negative = maximize
A_ub = [[1, 1], [2, 1]]  # Upper bound constraints
b_ub = [4, 5]

result = linprog(
    c,
    A_ub=A_ub,
    b_ub=b_ub,
    bounds=[(0, None), (0, None)],
    method='simplex'
)

print(f"Optimal solution: {result.x}")      # [1, 3]
print(f"Optimal value: {-result.fun}")      # 9

```

---

## üìä Complexity

### Worst Case

```
Exponential: O(2‚Åø) iterations possible
(Klee-Minty cube example)

```

### Average Case

```
Polynomial in practice: O(m) to O(3m) pivots
where m = number of constraints

Empirical: Very fast on real problems

```

### Why It Works Well

```
Despite exponential worst-case:
‚Ä¢ Typical problems reach optimum quickly
‚Ä¢ Heuristics (Dantzig's rule, steepest edge) help
‚Ä¢ Warm-starting enables fast updates

```

---

## üîÑ Variants

### Revised Simplex

```
‚Ä¢ More efficient: O(m¬≥) per iteration vs O(mn)
‚Ä¢ Works with basis matrix directly
‚Ä¢ Standard in modern solvers

```

### Dual Simplex

```
‚Ä¢ Maintains dual feasibility
‚Ä¢ Useful for re-optimization
‚Ä¢ Used in branch-and-bound

```

### Primal-Dual Methods

```
‚Ä¢ Maintain both primal and dual feasibility
‚Ä¢ Interior-point methods
‚Ä¢ Polynomial worst-case complexity

```

---

## üåç Applications

| Domain | Application | Variables |
|--------|-------------|-----------|
| **Manufacturing** | Production planning | 1000s |
| **Transportation** | Route optimization | 10,000s |
| **Finance** | Portfolio optimization | 100s-1000s |
| **ML** | SVM training (dual) | = # samples |
| **Networks** | Max flow | = # edges |

---

## üéì Historical Note

Invented by **George Dantzig** in 1947 while working for the U.S. Air Force. Named one of the top 10 algorithms of the 20th century!

**Impact:**
- Enabled operations research as a field
- Used in $100B+ decisions annually
- Foundation for integer programming

---

## üìö Resources

### Books
- **Linear Programming** - Dantzig (1963) - The original!
- **Introduction to Linear Optimization** - Bertsimas & Tsitsiklis
- **Linear Programming and Network Flows** - Bazaraa et al.

### Software
- **CPLEX** (IBM): Commercial, very fast
- **Gurobi**: Commercial, industry standard
- **GLPK**: Open-source
- **SciPy**: `scipy.optimize.linprog`

### Papers
- Dantzig (1951) - The simplex method
- Klee & Minty (1972) - Exponential example

---

‚¨ÖÔ∏è [Back: Linear Programming](../) | ‚û°Ô∏è [Next: Integer Programming](../../07_integer_programming/)

---

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=80&section=footer" width="100%"/>
</p>
