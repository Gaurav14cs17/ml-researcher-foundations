<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=120&section=header&text=Foundations&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-04-FF6B6B?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## ğŸ“‚ Subtopics

| Folder | Topic | Why Important |
|--------|-------|---------------|
| [01_calculus/](./01_calculus/) | Derivatives, Gradients, Hessian | Direction of steepest descent |
| [02_linear_algebra/](./02_linear_algebra/) | Matrices, Eigenvalues, SVD | Convergence rates, conditioning |

---

## ğŸ¯ What You'll Learn

```
+---------------------------------------------------------+

|                    FOUNDATIONS                          |
+---------------------------------------------------------+
|                                                         |
|   Calculus                    Linear Algebra            |
|   ---------                   --------------            |
|   â€¢ Partial derivatives       â€¢ Matrix operations       |
|   â€¢ Gradient âˆ‡f               â€¢ Eigenvalues Î»          |
|   â€¢ Hessian H                 â€¢ Positive definite      |
|   â€¢ Chain rule                â€¢ Condition number       |
|   â€¢ Taylor expansion          â€¢ Decompositions         |
|                                                         |
|   "Which way to go?"          "How fast to get there?" |
|                                                         |
+---------------------------------------------------------+

```

---

## ğŸŒ Why This Matters

| Concept | Used In | Example |
|---------|---------|---------|
| **Gradient** | All neural networks | Backpropagation in GPT |
| **Hessian** | Newton's method | Fast optimization |
| **Eigenvalues** | PCA, Spectral methods | Dimensionality reduction |
| **Condition number** | Numerical stability | Why training diverges |

---

## ğŸ”— Dependencies

```
foundations/
    |
    +-- calculus/ --------------+
    |   +-- gradients.md        |
    |   +-- hessian.md          +--> basic-methods/
    |   +-- chain-rule.md       |
    |                           |
    +-- linear-algebra/ --------+
        +-- eigenvalues.md
        +-- positive-definite.md

```

---

## ğŸ“š References

| Type | Title | Link |
|------|-------|------|
| ğŸ“– | Boyd: Convex Optimization | [Book](https://web.stanford.edu/~boyd/cvxbook/) |
| ğŸ“– | Nocedal: Numerical Optimization | [Book](https://www.springer.com/gp/book/9780387303031) |
| ğŸ¥ | 3Blue1Brown: Calculus | [YouTube](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) |
| ğŸ‡¨ğŸ‡³ | ä¼˜åŒ–åŸºç¡€æ•°å­¦ | [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/25383715) |
| ğŸ‡¨ğŸ‡³ | å‡¸ä¼˜åŒ–åŸºç¡€ | [CSDN](https://blog.csdn.net/qq_37466121/article/details/88619088) |
| ğŸ‡¨ğŸ‡³ | å¾®ç§¯åˆ†ä¸çº¿æ€§ä»£æ•° | [Bç«™](https://www.bilibili.com/video/BV1ys411472E) |

---

â¬…ï¸ [Back: Optimization](../) | â¡ï¸ [Next: Basic Methods](../02_basic_methods/)

---

## ğŸ”— Where This Topic Is Used

| Application | Usage |
|-------------|-------|
| **Machine Learning** | Core concept for ML systems |
| **Deep Learning** | Foundation for neural networks |
| **Research** | Important for understanding papers |

---

---

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=80&section=footer" width="100%"/>
</p>
