<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=120&section=header&text=Lagrange%20Multipliers&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-04-FF6B6B?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## üéØ Core Concept

**Lagrange multipliers** provide a method to find local extrema of a function subject to equality constraints. The key insight: at the optimum, the gradient of the objective is parallel to the gradient of the constraint.

---

## üìê Mathematical Formulation

### Problem

```
minimize   f(x)
subject to g(x) = 0

```

### Lagrangian Function

```
L(x, Œª) = f(x) + Œª·µÄg(x)

Where:
  x: decision variables
  Œª: Lagrange multipliers (one per constraint)

```

### Necessary Conditions

At optimum x*, Œª*:

```
1. Stationarity:  ‚àá‚ÇìL = ‚àáf(x*) + Œª·µÄ‚àág(x*) = 0
2. Feasibility:   g(x*) = 0

```

---

## üîë Geometric Intuition

```
At the optimum:
‚àáf(x*) ‚à• ‚àág(x*)  (parallel)

Why?
If ‚àáf not parallel to ‚àág, we could move along
the constraint surface to decrease f.

Therefore: ‚àáf(x*) = -Œª‚àág(x*)

```

**Visual:**

```
        ‚àáf ‚Üó
           ‚ï±
    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚óè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  (constraint surface g(x)=0)
           ‚ï≤
        ‚àág ‚Üò
        
At optimum: both gradients perpendicular to surface

```

---

## üí° Simple Example

**Problem:**

```
Minimize: f(x, y) = x¬≤ + y¬≤
Subject to: g(x, y) = x + y - 1 = 0

```

**Solution:**

```python
# Lagrangian: L = x¬≤ + y¬≤ + Œª(x + y - 1)

# Conditions:
# ‚àÇL/‚àÇx = 2x + Œª = 0  ‚Üí  x = -Œª/2
# ‚àÇL/‚àÇy = 2y + Œª = 0  ‚Üí  y = -Œª/2
# ‚àÇL/‚àÇŒª = x + y - 1 = 0

# From first two: x = y
# From third: 2x = 1  ‚Üí  x = y = 0.5

# Solution: (x*, y*) = (0.5, 0.5)
# Optimal value: f* = 0.5
# Multiplier: Œª* = -1

```

---

## üíª Implementation

```python
import numpy as np
from scipy.optimize import minimize

def objective(X):
    """f(x,y) = x¬≤ + y¬≤"""
    return X[0]**2 + X[1]**2

def constraint(X):
    """g(x,y) = x + y - 1"""
    return X[0] + X[1] - 1

# Solve with scipy
result = minimize(
    objective,
    x0=[0, 0],
    constraints={'type': 'eq', 'fun': constraint},
    method='SLSQP'
)

print(f"Optimal point: {result.x}")           # [0.5, 0.5]
print(f"Optimal value: {result.fun}")         # 0.5
print(f"Multiplier: {result.get('lagrange')}")  # -1.0

```

---

## üåç Applications in ML

| Application | Objective f(x) | Constraint g(x) |
|-------------|----------------|-----------------|
| **Max Entropy** | H(p) = -Œ£p¬∑log(p) | Œ£p·µ¢ = 1 |
| **SVM (Hard)** | ¬Ω\|\|w\|\|¬≤ | y·µ¢(w·µÄx·µ¢ + b) = 1 |
| **PCA** | maximize variance | \|\|w\|\| = 1 |
| **GMM** | log-likelihood | Œ£œÄ‚Çñ = 1 |

---

## üîÑ Extension to Multiple Constraints

For m constraints g·µ¢(x) = 0:

```
L(x, Œª) = f(x) + Œ£·µ¢Œª·µ¢g·µ¢(x)

Conditions:
‚àá‚ÇìL = ‚àáf + Œ£·µ¢Œª·µ¢‚àág·µ¢ = 0
g·µ¢(x) = 0, ‚àÄi

```

**Interpretation:** ‚àáf is in the span of {‚àág‚ÇÅ, ..., ‚àág‚Çò}

---

## üìö Theory

### Second-Order Conditions

For x* to be a local minimum:

```
‚àá¬≤‚Çì‚ÇìL(x*, Œª*) is positive definite on the tangent space
T = {v : ‚àág(x*)·µÄv = 0}

```

### Regularity Condition

**LICQ (Linear Independence Constraint Qualification):**

```
{‚àág‚ÇÅ(x*), ..., ‚àág‚Çò(x*)} are linearly independent

```

Ensures uniqueness of Œª*.

---

## üìê DETAILED MATHEMATICAL DERIVATIONS

### 1. Why Lagrange Multipliers Work: Complete Proof

**Theorem (First-Order Necessary Conditions):** Let x* be a local minimum of f(x) subject to g(x) = 0, where f and g are continuously differentiable, and ‚àág(x*) ‚â† 0. Then there exists Œª* such that:

```
‚àáf(x*) + Œª*‚àág(x*) = 0

```

**Proof:**

```
Step 1: Define feasible directions
A direction d is feasible if there exists Œ± > 0 such that:
x* + Œ±d satisfies g(x* + Œ±d) ‚âà 0 for small Œ±

Taylor expansion:
g(x* + Œ±d) ‚âà g(x*) + Œ±‚àág(x*)·µÄd
           = Œ±‚àág(x*)·µÄd           (since g(x*) = 0)

For feasibility: ‚àág(x*)·µÄd = 0

So: Feasible directions lie in tangent space T = {d : ‚àág(x*)·µÄd = 0}

Step 2: Optimality implies no descent direction
Since x* is a local minimum, f cannot decrease along any feasible direction:
‚àáf(x*)·µÄd ‚â• 0  for all d ‚àà T

Step 3: Characterize T‚ä• (orthogonal complement)
T = {d : ‚àág(x*)·µÄd = 0}
T‚ä• = span(‚àág(x*))

Step 4: ‚àáf must be in T‚ä•
If ‚àáf(x*) ‚àâ T‚ä•, then ‚àáf has a component in T.
Let d = -projection of ‚àáf onto T
Then ‚àáf(x*)·µÄd < 0 (descent direction in T)
Contradiction! (x* wouldn't be optimal)

Therefore: ‚àáf(x*) ‚àà T‚ä• = span(‚àág(x*))

Step 5: Conclusion
‚àáf(x*) = -Œª*‚àág(x*) for some Œª* ‚àà ‚Ñù
‚üπ ‚àáf(x*) + Œª*‚àág(x*) = 0  ‚àé

```

**Geometric Interpretation:**

```
At optimum, ‚àáf and ‚àág are parallel:

   Level curve g(x) = 0
   ------‚óè------  (constraint)
        /|\
       / | \
      ‚àáf ‚àág

If not parallel, we could move along constraint
to decrease f ‚Üí not optimal!

```

---

### 2. Second-Order Sufficient Conditions

**Theorem:** If at (x*, Œª*):
1. First-order conditions hold: ‚àáL = 0
2. LICQ holds: ‚àág(x*) ‚â† 0
3. ‚àá¬≤‚Çì‚ÇìL(x*, Œª*) is positive definite on T

Then x* is a strict local minimum.

**Proof Sketch:**

```
Step 1: Taylor expansion of f along constraint
For d ‚àà T (feasible direction):
f(x* + d) ‚âà f(x*) + ‚àáf(x*)·µÄd + (1/2)d·µÄ‚àá¬≤f(x*)d

Step 2: Use first-order conditions
‚àáf(x*)·µÄd = -Œª*‚àág(x*)·µÄd = 0  (since d ‚àà T)

So: f(x* + d) ‚âà f(x*) + (1/2)d·µÄ‚àá¬≤f(x*)d

Step 3: Hessian of Lagrangian
‚àá¬≤L = ‚àá¬≤f + Œª*‚àá¬≤g

On T, ‚àá¬≤g contribution vanishes (constrained Hessian):
d·µÄ‚àá¬≤L d = d·µÄ‚àá¬≤f d + Œª*d·µÄ‚àá¬≤g d ‚âà d·µÄ‚àá¬≤f d

Step 4: Positive definiteness
If ‚àá¬≤L ‚âª 0 on T:
f(x* + d) > f(x*) for all d ‚àà T, d ‚â† 0
‚üπ x* is strict local minimum  ‚àé

```

---

### 3. Multiple Constraints: General Case

**Problem:**

```
minimize   f(x)
subject to g‚ÇÅ(x) = 0
           g‚ÇÇ(x) = 0
           ...
           g‚Çò(x) = 0

```

**Lagrangian:**

```
L(x, Œª) = f(x) + Œ£·µ¢ Œª·µ¢g·µ¢(x)
        = f(x) + Œª·µÄg(x)

```

**First-Order Necessary Conditions (KKT for equality):**

```
‚àá‚ÇìL = ‚àáf(x*) + Œ£·µ¢ Œª·µ¢*‚àág·µ¢(x*) = 0    (Stationarity)
g·µ¢(x*) = 0, ‚àÄi                      (Feasibility)

```

**Geometric interpretation:**

```
‚àáf(x*) ‚àà span{‚àág‚ÇÅ(x*), ..., ‚àág‚Çò(x*)}

That is:
‚àáf(x*) = -Œ£·µ¢ Œª·µ¢*‚àág·µ¢(x*)

Tangent space: T = {d : ‚àág·µ¢(x*)·µÄd = 0, ‚àÄi}
Normal space: N = span{‚àág‚ÇÅ, ..., ‚àág‚Çò}

At optimum: ‚àáf ‚àà N

```

---

### 4. Worked Example: Constrained Least Squares

**Problem:**

```
minimize   f(x) = (1/2)||Ax - b||¬≤
subject to Cx = d

```

**Solution:**

```
Step 1: Lagrangian
L(x, Œª) = (1/2)||Ax - b||¬≤ + Œª·µÄ(Cx - d)
        = (1/2)(Ax - b)·µÄ(Ax - b) + Œª·µÄ(Cx - d)

Step 2: Compute gradients
‚àÇL/‚àÇx = A·µÄ(Ax - b) + C·µÄŒª = 0
‚àÇL/‚àÇŒª = Cx - d = 0

Step 3: Solve system
From first equation: A·µÄAx + C·µÄŒª = A·µÄb
From second: Cx = d

In matrix form:
[A·µÄA  C·µÄ] [x]   [A·µÄb]
[C    0 ] [Œª] = [d  ]

This is the KKT system!

Step 4: Solution (if invertible)
[x*]   [A·µÄA  C·µÄ]‚Åª¬π [A·µÄb]
[Œª*] = [C    0 ]   [d  ]

```

**Implementation:**

```python
import numpy as np

def constrained_least_squares(A, b, C, d):
    """
    Solve: min ||Ax - b||¬≤  s.t. Cx = d
    """
    m, n = A.shape
    p = C.shape[0]
    
    # Build KKT system
    K = np.block([[A.T @ A,  C.T    ],
                  [C,        np.zeros((p, p))]])
    
    rhs = np.concatenate([A.T @ b, d])
    
    # Solve
    sol = np.linalg.solve(K, rhs)
    
    x_opt = sol[:n]
    lambda_opt = sol[n:]
    
    return x_opt, lambda_opt

# Example
np.random.seed(42)
m, n, p = 10, 5, 2

A = np.random.randn(m, n)
b = np.random.randn(m)
C = np.random.randn(p, n)
d = np.random.randn(p)

x_opt, lambda_opt = constrained_least_squares(A, b, C, d)

print(f"Optimal x: {x_opt}")
print(f"Constraint satisfied: {np.allclose(C @ x_opt, d)}")
print(f"Objective: {0.5 * np.linalg.norm(A @ x_opt - b)**2:.6f}")

```

---

### 5. Connection to SVM (Support Vector Machines)

**Primal Problem (Hard-margin SVM):**

```
minimize   (1/2)||w||¬≤
subject to y·µ¢(w·µÄx·µ¢ + b) ‚â• 1,  ‚àÄi

```

**Lagrangian:**

```
L(w, b, Œ±) = (1/2)||w||¬≤ - Œ£·µ¢ Œ±·µ¢[y·µ¢(w·µÄx·µ¢ + b) - 1]

Where Œ±·µ¢ ‚â• 0 are Lagrange multipliers

```

**KKT Conditions:**

```
‚àÇL/‚àÇw = w - Œ£·µ¢ Œ±·µ¢y·µ¢x·µ¢ = 0  ‚üπ  w = Œ£·µ¢ Œ±·µ¢y·µ¢x·µ¢
‚àÇL/‚àÇb = -Œ£·µ¢ Œ±·µ¢y·µ¢ = 0      ‚üπ  Œ£·µ¢ Œ±·µ¢y·µ¢ = 0

Complementary slackness:
  Œ±·µ¢[y·µ¢(w·µÄx·µ¢ + b) - 1] = 0,  ‚àÄi

```

**Dual Problem (substituting w = Œ£·µ¢ Œ±·µ¢y·µ¢x·µ¢):**

```
maximize   Œ£·µ¢ Œ±·µ¢ - (1/2)Œ£·µ¢Œ£‚±º Œ±·µ¢Œ±‚±ºy·µ¢y‚±ºx·µ¢·µÄx‚±º
subject to Œ±·µ¢ ‚â• 0, Œ£·µ¢ Œ±·µ¢y·µ¢ = 0

```

**Support vectors:** Points where Œ±·µ¢ > 0 (constraint is active)

---

### 6. Lagrange Multipliers Interpretation

**Economic interpretation:**

```
Œª* = Shadow price = Marginal value of relaxing constraint

If constraint changes to g(x) = Œµ (small Œµ):
f(x*(Œµ)) ‚âà f(x*(0)) - Œª*Œµ

Œª* tells you how much f would improve if constraint relaxed!

```

**Example:**

```
Maximize profit f(x) subject to budget g(x) = 0

Œª* > 0: Increasing budget by $1 increases profit by $Œª*
Œª* = 0: Constraint not binding (slack in budget)

```

---

### 7. Research Paper Applications

| Paper/Method | Optimization Problem | Constraint | Œª Interpretation |
|--------------|---------------------|------------|------------------|
| **PCA** | max w·µÄŒ£w | w·µÄw = 1 | Eigenvalue! |
| **Fisher LDA** | max w·µÄS_Bw/w·µÄS_Ww | w·µÄS_Ww = 1 | Generalized eigenvalue |
| **SVM** | min ¬Ω\|\|w\|\|¬≤ | y(wx + b) ‚â• 1 | Support vector weights |
| **Max Entropy** | max -Œ£p log p | Œ£p = 1, ùîº[f] = Œº | Moment constraints |
| **CCA** | max u·µÄXY·µÄv | u·µÄu = v·µÄv = 1 | Canonical correlation |

**PCA Derivation:**

```
Problem: max_w w·µÄŒ£w  s.t. ||w|| = 1

Lagrangian: L = w·µÄŒ£w - Œª(w·µÄw - 1)

‚àÇL/‚àÇw = 2Œ£w - 2Œªw = 0
‚üπ Œ£w = Œªw

This is eigenvalue equation!
w* = eigenvector of Œ£
Œª* = eigenvalue (variance captured)

```

---

### 8. Practical Tips for Research Papers

**When you see Lagrange multipliers in papers:**

1. **Look for the primal-dual formulation**
   ```
   Primal: min f(x) s.t. g(x) = 0
   Dual:   max_Œª min_x L(x, Œª)
   ```

2. **Check for duality gap**
   ```
   Strong duality: Primal opt = Dual opt
   Holds for convex problems with constraints qualification
   ```

3. **Complementary slackness** (for inequalities):
   ```
   Œ±·µ¢ g·µ¢(x) = 0
   
   Either Œ±·µ¢ = 0 (constraint inactive) or g·µ¢(x) = 0 (binding)
   ```

4. **Augmented Lagrangian method** (ADMM):
   ```
   L_œÅ(x, Œª) = f(x) + Œª·µÄg(x) + (œÅ/2)||g(x)||¬≤
   
   Add quadratic penalty for robustness
   ```

---

### 9. Connection to Modern ML

**Neural Network Training with Constraints:**

```python
# Example: Train NN with orthogonal weights
# Constraint: W·µÄW = I

def augmented_lagrangian_step(W, lambda_mat, rho):
    """
    One step of augmented Lagrangian optimization
    """
    # Standard training loss
    loss = compute_loss(W)
    
    # Constraint: W·µÄW - I = 0
    constraint = W.T @ W - torch.eye(W.shape[1])
    
    # Augmented Lagrangian
    aug_loss = loss + torch.trace(lambda_mat @ constraint) + \
               (rho/2) * torch.norm(constraint, 'fro')**2
    
    # Gradient descent
    aug_loss.backward()
    optimizer.step()
    
    # Update multiplier (dual ascent)
    lambda_mat = lambda_mat + rho * constraint.detach()
    
    return lambda_mat

```

---

### 10. Advanced: Constrained Optimization in Transformers

**LayerNorm as constrained optimization:**

```
Problem: Normalize activations to zero mean, unit variance

Can be viewed as:
minimize   ||h - h_norm||¬≤
subject to mean(h_norm) = 0, var(h_norm) = 1

Using Lagrange multipliers:
h_norm = (h - Œº) / œÉ

where Œº, œÉ are the multipliers (learned scale/shift applied after)

```

**Attention with constraints:**

```
Attention weights: softmax(scores) implicitly solves:
maximize   Œ£·µ¢ Œ±·µ¢ ¬∑ score·µ¢
subject to Œ£·µ¢ Œ±·µ¢ = 1, Œ±·µ¢ ‚â• 0

Lagrangian: L = Œ£·µ¢ Œ±·µ¢ ¬∑ score·µ¢ - Œª(Œ£·µ¢ Œ±·µ¢ - 1)

Solution: Œ±·µ¢* = exp(score·µ¢) / Œ£‚±º exp(score‚±º) = softmax(scores)·µ¢

```

---

##

## üéì Historical Note

Developed by **Joseph-Louis Lagrange** (1736-1813) in his work on celestial mechanics. The method revolutionized constrained optimization and remains fundamental 250+ years later!

---

## üìö Resources

### Books
- **Convex Optimization** - Boyd & Vandenberghe (¬ß5.1)
- **Numerical Optimization** - Nocedal & Wright (Ch 12)

### Papers
- Lagrange (1788) - M√©canique Analytique

### Online
- 3Blue1Brown: Lagrange Multipliers
- Khan Academy: Constrained Optimization

---

‚¨ÖÔ∏è [Back: KKT](../01_kkt/) | ‚¨ÜÔ∏è [Up: Constrained Optimization](../)

---

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=80&section=footer" width="100%"/>
</p>
