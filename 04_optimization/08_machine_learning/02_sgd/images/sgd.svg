<?xml version="1.0" ?>
<ns0:svg xmlns:ns0="http://www.w3.org/2000/svg" viewBox="0.0 0.0 1800.0 900.0">
  <ns0:defs>
    <ns0:linearGradient id="sgdBg" x1="0%" y1="0%" x2="100%" y2="100%">
      <ns0:stop offset="0%" style="stop-color:#ffffff"/>
      <ns0:stop offset="100%" style="stop-color:#2d2d2d"/>
    </ns0:linearGradient>
  </ns0:defs>
  <ns0:rect width="1800.0" height="900.0" fill="#f8f9fa" rx="8"/>
  <ns0:text x="400" y="35" text-anchor="middle" fill="#1565c0" font-size="22" font-weight="bold">Stochastic Gradient Descent</ns0:text>
  <ns0:rect x="200" y="60" width="400" height="70" rx="10" fill="#1e3a5f" stroke="#007bff" stroke-width="2"/>
  <ns0:text x="400" y="95" text-anchor="middle" fill="#1565c0" font-size="16">θₜ₊₁ = θₜ - η ∇L_B(θₜ)</ns0:text>
  <ns0:text x="400" y="118" text-anchor="middle" fill="#1565c0" font-size="11">B = mini-batch, η = learning rate</ns0:text>
  <ns0:rect x="50" y="150" width="230" height="110" rx="8" fill="#134e4a" stroke="#10b981" stroke-width="2"/>
  <ns0:text x="165" y="175" text-anchor="middle" fill="#10b981" font-size="13" font-weight="bold">+ Momentum</ns0:text>
  <ns0:text x="165" y="200" text-anchor="middle" fill="#2e7d32" font-size="11">vₜ = βvₜ₋₁ + ∇L</ns0:text>
  <ns0:text x="165" y="220" text-anchor="middle" fill="#2e7d32" font-size="11">θ ← θ - ηvₜ</ns0:text>
  <ns0:text x="165" y="245" text-anchor="middle" fill="#2e7d32" font-size="10">Accelerates convergence</ns0:text>
  <ns0:rect x="290" y="150" width="230" height="110" rx="8" fill="#4c1d95" stroke="#a78bfa" stroke-width="2"/>
  <ns0:text x="405" y="270.0" text-anchor="middle" fill="#a78bfa" font-size="13" font-weight="bold">+ Nesterov</ns0:text>
  <ns0:text x="405" y="295.0" text-anchor="middle" fill="#ddd6fe" font-size="11">Look-ahead gradient</ns0:text>
  <ns0:text x="405" y="320.0" text-anchor="middle" fill="#ddd6fe" font-size="11">∇L(θ + βvₜ₋₁)</ns0:text>
  <ns0:text x="405" y="345.0" text-anchor="middle" fill="#c4b5fd" font-size="10">Better convergence</ns0:text>
  <ns0:rect x="530" y="150" width="220" height="110" rx="8" fill="#7f1d1d" stroke="#dc3545" stroke-width="2"/>
  <ns0:text x="640" y="370.0" text-anchor="middle" fill="#c62828" font-size="13" font-weight="bold">+ Weight Decay</ns0:text>
  <ns0:text x="640" y="395.0" text-anchor="middle" fill="#c62828" font-size="11">θ ← θ - ηλθ - η∇L</ns0:text>
  <ns0:text x="640" y="420.0" text-anchor="middle" fill="#c62828" font-size="11">Decoupled in AdamW</ns0:text>
  <ns0:text x="640" y="445.0" text-anchor="middle" fill="#c62828" font-size="10">Regularization</ns0:text>
  <ns0:rect x="100" y="280" width="600" height="90" rx="10" fill="#1a237e" stroke="#fd7e14" stroke-width="2"/>
  <ns0:text x="400" y="470.0" text-anchor="middle" fill="#e65100" font-size="14" font-weight="bold">Batch Size Effects</ns0:text>
  <ns0:text x="250" y="495.0" text-anchor="middle" fill="#fef3c7" font-size="11">Small batch: high noise, better generalization</ns0:text>
  <ns0:text x="550" y="520.0" text-anchor="middle" fill="#fef3c7" font-size="11">Large batch: stable, needs lr scaling</ns0:text>
  <ns0:text x="400" y="545.0" text-anchor="middle" fill="#e65100" font-size="10">Linear scaling rule: lr ∝ batch_size</ns0:text>
</ns0:svg>