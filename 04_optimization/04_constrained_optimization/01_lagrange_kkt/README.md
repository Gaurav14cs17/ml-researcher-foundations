<!-- Animated Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=120&section=header&text=Lagrange%20Multipliers%20%26%20KKT&fontSize=32&fontColor=fff&animation=twinkling&fontAlignY=35" width="100%"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Section-04-FF6B6B?style=for-the-badge&logo=bookstack&logoColor=white" alt="Section"/>
  <img src="https://img.shields.io/badge/Author-Gaurav_Goswami-blue?style=for-the-badge" alt="Author"/>
  <img src="https://img.shields.io/badge/Updated-December_2025-green?style=for-the-badge" alt="Updated"/>
</p>

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

---

## ğŸ¯ Overview

This section covers the two fundamental tools for constrained optimization:
- **Lagrange Multipliers**: For equality constraints
- **KKT Conditions**: For equality AND inequality constraints

---

## ğŸ“ Part 1: Lagrangian Method

### Problem Formulation

```
minimize    f(x)
subject to  g(x) = 0

where g(x) = [gâ‚(x), gâ‚‚(x), ..., gâ‚˜(x)]áµ€
```

### The Lagrangian Function

```
L(x, Î») = f(x) + Î»áµ€g(x)
        = f(x) + Î£áµ¢ Î»áµ¢gáµ¢(x)

where Î» = [Î»â‚, Î»â‚‚, ..., Î»â‚˜]áµ€ are Lagrange multipliers
```

### First-Order Necessary Conditions

```
At optimum (x*, Î»*):

âˆ‡â‚“L = âˆ‡f(x*) + Î£áµ¢ Î»áµ¢*âˆ‡gáµ¢(x*) = 0   (Stationarity)
âˆ‡Î»L = g(x*) = 0                      (Feasibility)

Geometric interpretation:
âˆ‡f(x*) = -Î£áµ¢ Î»áµ¢*âˆ‡gáµ¢(x*)

"The objective gradient is a linear combination of constraint gradients"
```

---

## ğŸ“ Proof: Why Lagrange Multipliers Work

**Theorem:** Let x* be a local minimum subject to g(x) = 0. If âˆ‡g(x*) has full rank, then there exists Î»* such that âˆ‡f(x*) + Î»*áµ€âˆ‡g(x*) = 0.

**Proof:**

```
Step 1: Define the tangent space
T = {d âˆˆ â„â¿ : âˆ‡g(x*)áµ€d = 0}

This is the set of all directions that stay on the constraint surface
(to first order).

Step 2: Optimality implies no descent in T
If x* is a local minimum, then for all d âˆˆ T:
âˆ‡f(x*)áµ€d â‰¥ 0

(Otherwise we could decrease f while staying feasible)

But also -d âˆˆ T, so:
âˆ‡f(x*)áµ€(-d) â‰¥ 0  âŸ¹  âˆ‡f(x*)áµ€d â‰¤ 0

Therefore: âˆ‡f(x*)áµ€d = 0 for all d âˆˆ T

Step 3: Characterize the orthogonal complement
T = null(âˆ‡g(x*)áµ€)
TâŠ¥ = range(âˆ‡g(x*)) = span of columns of âˆ‡g(x*)

Step 4: âˆ‡f must be in TâŠ¥
Since âˆ‡f(x*)áµ€d = 0 for all d âˆˆ T:
âˆ‡f(x*) âŠ¥ T  âŸ¹  âˆ‡f(x*) âˆˆ TâŠ¥

Step 5: Express âˆ‡f as combination
âˆ‡f(x*) âˆˆ TâŠ¥ = range(âˆ‡g(x*))

Therefore: âˆ‡f(x*) = -âˆ‡g(x*)Î»* for some Î»* âˆˆ â„áµ

Rearranging: âˆ‡f(x*) + âˆ‡g(x*)Î»* = 0  âˆ
```

---

## ğŸ“ Part 2: KKT Conditions

### Problem with Inequalities

```
minimize    f(x)
subject to  gáµ¢(x) â‰¤ 0,  i = 1,...,m   (inequalities)
            hâ±¼(x) = 0,  j = 1,...,p   (equalities)
```

### The KKT Lagrangian

```
L(x, Î¼, Î») = f(x) + Î£áµ¢ Î¼áµ¢gáµ¢(x) + Î£â±¼ Î»â±¼hâ±¼(x)

where:
â€¢ Î¼áµ¢ â‰¥ 0: multipliers for inequalities
â€¢ Î»â±¼ âˆˆ â„: multipliers for equalities
```

### The 5 KKT Conditions

```
At optimum (x*, Î¼*, Î»*):

1. STATIONARITY
   âˆ‡f(x*) + Î£áµ¢ Î¼áµ¢*âˆ‡gáµ¢(x*) + Î£â±¼ Î»â±¼*âˆ‡hâ±¼(x*) = 0

2. PRIMAL FEASIBILITY
   gáµ¢(x*) â‰¤ 0  for all i
   hâ±¼(x*) = 0  for all j

3. DUAL FEASIBILITY
   Î¼áµ¢* â‰¥ 0  for all i

4. COMPLEMENTARY SLACKNESS
   Î¼áµ¢* Â· gáµ¢(x*) = 0  for all i

5. (For convex problems) SUFFICIENCY
   If f, gáµ¢ convex and hâ±¼ affine â†’ KKT sufficient for optimality
```

---

## ğŸ“ Understanding Complementary Slackness

```
Î¼áµ¢* Â· gáµ¢(x*) = 0 means:

Either Î¼áµ¢* = 0  (multiplier is zero)
Or     gáµ¢(x*) = 0  (constraint is active/binding)

Visual Interpretation:

Case 1: INACTIVE constraint (gáµ¢ < 0)
+-----------------------------------+
|   Optimal point inside region     |
|                                   |
|         â€¢  x*                     |
|        â•± â•²                        |
|       â•±   â•²  boundary gáµ¢ = 0     |
|      â•±     â•²                      |
|                                   |
|   Constraint doesn't matter       |
|   âŸ¹ Î¼áµ¢* = 0                      |
+-----------------------------------+

Case 2: ACTIVE constraint (gáµ¢ = 0)
+-----------------------------------+
|   Optimal point on boundary       |
|                                   |
|      ----â—---- boundary           |
|         x*                        |
|        â•± â•²                        |
|       â•±   â•²                       |
|                                   |
|   Constraint is binding           |
|   âŸ¹ Î¼áµ¢* > 0 possible             |
+-----------------------------------+
```

---

## ğŸ“ Worked Example: Quadratic with Inequality

### Problem

```
minimize   f(x,y) = xÂ² + yÂ²
subject to g(x,y) = 1 - x - y â‰¤ 0  (i.e., x + y â‰¥ 1)
```

### Step 1: Write Lagrangian

```
L(x, y, Î¼) = xÂ² + yÂ² + Î¼(1 - x - y)
```

### Step 2: KKT Conditions

```
Stationarity:
âˆ‚L/âˆ‚x = 2x - Î¼ = 0  âŸ¹  x = Î¼/2
âˆ‚L/âˆ‚y = 2y - Î¼ = 0  âŸ¹  y = Î¼/2

Primal feasibility:
1 - x - y â‰¤ 0  âŸ¹  x + y â‰¥ 1

Dual feasibility:
Î¼ â‰¥ 0

Complementary slackness:
Î¼(1 - x - y) = 0
```

### Step 3: Solve by Cases

**Case A: Î¼ = 0 (constraint inactive)**
```
x = 0, y = 0
Check: 1 - 0 - 0 = 1 > 0  âœ— (violates primal feasibility!)
```

**Case B: Î¼ > 0 (constraint active)**
```
From complementary slackness: x + y = 1
From stationarity: x = y = Î¼/2
Therefore: Î¼/2 + Î¼/2 = 1 âŸ¹ Î¼ = 1 > 0 âœ“

Solution: x* = y* = 1/2, Î¼* = 1
Optimal value: f* = 1/4 + 1/4 = 1/2
```

---

## ğŸ’» Code Implementation

```python
import numpy as np
from scipy.optimize import minimize

def solve_kkt_example():
    """
    Solve: min xÂ² + yÂ²
           s.t. x + y â‰¥ 1
    """
    def f(xy):
        return xy[0]**2 + xy[1]**2
    
    def g(xy):
        return xy[0] + xy[1] - 1  # x + y - 1 â‰¥ 0
    
    # Solve with scipy (SLSQP uses KKT internally)
    result = minimize(
        f,
        x0=[0.5, 0.5],
        constraints={'type': 'ineq', 'fun': g}  # g(x) â‰¥ 0
    )
    
    print(f"Optimal x: {result.x}")
    print(f"Optimal f(x): {result.fun}")
    print(f"Constraint g(x): {g(result.x)}")
    
    # Verify KKT manually
    x, y = result.x
    grad_f = np.array([2*x, 2*y])
    grad_g = np.array([1, 1])
    
    # From stationarity: grad_f = Î¼ * grad_g
    mu = grad_f[0] / grad_g[0]
    print(f"\nKKT verification:")
    print(f"Î¼* = {mu}")
    print(f"Î¼ â‰¥ 0: {mu >= 0}")
    print(f"Complementary slackness (Î¼*g = 0): {abs(mu * (1 - x - y)) < 1e-6}")
    
    return result

result = solve_kkt_example()
```

---

## ğŸ“ KKT for SVM (Support Vector Machine)

### Primal Problem

```
minimize    (1/2)||w||Â²
subject to  yáµ¢(wáµ€xáµ¢ + b) â‰¥ 1,  i = 1,...,n

Or equivalently:
minimize    (1/2)||w||Â²
subject to  1 - yáµ¢(wáµ€xáµ¢ + b) â‰¤ 0
```

### Lagrangian

```
L(w, b, Î±) = (1/2)||w||Â² - Î£áµ¢ Î±áµ¢[yáµ¢(wáµ€xáµ¢ + b) - 1]
           = (1/2)||w||Â² - Î£áµ¢ Î±áµ¢yáµ¢wáµ€xáµ¢ - bÎ£áµ¢ Î±áµ¢yáµ¢ + Î£áµ¢ Î±áµ¢
```

### KKT Conditions

```
Stationarity:
âˆ‚L/âˆ‚w = w - Î£áµ¢ Î±áµ¢yáµ¢xáµ¢ = 0  âŸ¹  w = Î£áµ¢ Î±áµ¢yáµ¢xáµ¢
âˆ‚L/âˆ‚b = -Î£áµ¢ Î±áµ¢yáµ¢ = 0        âŸ¹  Î£áµ¢ Î±áµ¢yáµ¢ = 0

Dual feasibility:
Î±áµ¢ â‰¥ 0

Complementary slackness:
Î±áµ¢[yáµ¢(wáµ€xáµ¢ + b) - 1] = 0

Interpretation:
â€¢ Î±áµ¢ = 0: Point is NOT a support vector
â€¢ Î±áµ¢ > 0: Point IS a support vector (on margin)
```

### Dual Problem

```
Substituting w = Î£áµ¢ Î±áµ¢yáµ¢xáµ¢ into L:

maximize   Î£áµ¢ Î±áµ¢ - (1/2)Î£áµ¢Î£â±¼ Î±áµ¢Î±â±¼yáµ¢yâ±¼xáµ¢áµ€xâ±¼
subject to Î±áµ¢ â‰¥ 0
           Î£áµ¢ Î±áµ¢yáµ¢ = 0

This is a quadratic program in Î±!
```

---

## ğŸ“ Economic Interpretation: Shadow Prices

```
The Lagrange multiplier Î»* has economic meaning:

Î»* = âˆ‚f*/âˆ‚b  (sensitivity of optimal value to constraint)

Example:
â€¢ Minimize cost f(x) subject to production g(x) â‰¥ b
â€¢ Î»* = marginal cost of producing one more unit
â€¢ This is the "shadow price" of production capacity

In ML:
â€¢ SVM: Î±áµ¢ = "importance" of data point i
â€¢ Large Î±áµ¢ âŸ¹ Important support vector
â€¢ Zero Î±áµ¢ âŸ¹ Point doesn't affect decision boundary
```

---

## ğŸ“Š Comparison

| Aspect | Lagrange | KKT |
|--------|----------|-----|
| **Constraints** | Equality only | Equality + Inequality |
| **Multipliers** | Î» âˆˆ â„ | Î¼ â‰¥ 0 for inequalities |
| **Extra condition** | None | Complementary slackness |
| **Applications** | Physics, simple ML | SVM, RL, general optimization |

---

## ğŸ”— Applications

| Application | Constraint Type | Example |
|-------------|-----------------|---------|
| **SVM** | Inequality | Margin â‰¥ 1 for all points |
| **Portfolio** | Equality + Inequality | Weights sum to 1, non-negative |
| **Physics** | Equality | Conserve energy/momentum |
| **RL (TRPO, PPO)** | KL constraint | Trust region |
| **Optimal Control** | Dynamics as equality | Trajectory optimization |

---

## ğŸ“š Resources

| Type | Title | Link |
|------|-------|------|
| ğŸ“– | Boyd CVX Ch.5 | [Free PDF](https://web.stanford.edu/~boyd/cvxbook/) |
| ğŸ“– | Nocedal Ch.12 | [Springer](https://link.springer.com/book/10.1007/978-0-387-40065-5) |
| ğŸ¥ | KKT Conditions | [YouTube](https://www.youtube.com/watch?v=uh1Dk68cfWs) |
| ğŸ“„ | Original KKT Paper | [1951](https://doi.org/10.1525/9780520347663-014) |
| ğŸ‡¨ğŸ‡³ | çŸ¥ä¹ KKTæ¡ä»¶ | [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/38163970) |

---

â¬…ï¸ [Back: Constrained Optimization](../) | â¡ï¸ [Next: Main Constrained Optimization](../../05_constrained_optimization/)

---

<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=FF6B6B&height=80&section=footer" width="100%"/>
</p>
